[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "makedirs",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "ArgumentParser",
        "importPath": "argparse",
        "description": "argparse",
        "isExtraImport": true,
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "CfgNode",
        "importPath": "third_parties.yacs",
        "description": "third_parties.yacs",
        "isExtraImport": true,
        "detail": "third_parties.yacs",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "Rodrigues",
        "importPath": "cv2",
        "description": "cv2",
        "isExtraImport": true,
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "torch.utils.data",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "load_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "load_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "tile_images",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "ImageWriter",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b3ch_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "ImageWriter",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b3ch_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "load_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "save_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_3ch_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "load_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "save_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_3ch_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "ImageWriter",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b3ch_image",
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "isExtraImport": true,
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "isExtraImport": true,
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "isExtraImport": true,
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "body_pose_to_body_RTs",
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "isExtraImport": true,
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "get_canonical_global_tfms",
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "isExtraImport": true,
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "approx_gaussian_bone_volumes",
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "isExtraImport": true,
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "isExtraImport": true,
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "isExtraImport": true,
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "apply_global_tfm_to_camera",
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "isExtraImport": true,
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "get_rays_from_KRT",
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "isExtraImport": true,
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "rays_intersect_3d_bbox",
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "isExtraImport": true,
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "list_files",
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "isExtraImport": true,
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "split_path",
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "isExtraImport": true,
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "list_files",
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "isExtraImport": true,
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "split_path",
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "isExtraImport": true,
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "list_files",
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "isExtraImport": true,
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "split_path",
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "isExtraImport": true,
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "split_path",
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "isExtraImport": true,
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "args",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "cfg",
        "importPath": "configs",
        "description": "configs",
        "isExtraImport": true,
        "detail": "configs",
        "documentation": {}
    },
    {
        "label": "imp",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imp",
        "description": "imp",
        "detail": "imp",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "ConvDecoder3D",
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "isExtraImport": true,
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "initseq",
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "isExtraImport": true,
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "initseq",
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "isExtraImport": true,
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "RodriguesModule",
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "isExtraImport": true,
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "MotionBasisComputer",
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "isExtraImport": true,
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "set_requires_grad",
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "isExtraImport": true,
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "load",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "BuildExtension",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "CUDAExtension",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "CUDAExtension",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "BuildExtension",
        "importPath": "torch.utils.cpp_extension",
        "description": "torch.utils.cpp_extension",
        "isExtraImport": true,
        "detail": "torch.utils.cpp_extension",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Function",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "custom_bwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "custom_fwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "custom_bwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "custom_fwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "custom_bwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "custom_fwd",
        "importPath": "torch.cuda.amp",
        "description": "torch.cuda.amp",
        "isExtraImport": true,
        "detail": "torch.cuda.amp",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "load_positional_embedder",
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "isExtraImport": true,
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_canonical_mlp",
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "isExtraImport": true,
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_mweight_vol_decoder",
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "isExtraImport": true,
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_pose_decoder",
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "isExtraImport": true,
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_non_rigid_motion_mlp",
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "isExtraImport": true,
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "tinycudann",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tinycudann",
        "description": "tinycudann",
        "detail": "tinycudann",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tqdm",
        "description": "tqdm",
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "LPIPS",
        "importPath": "third_parties.lpips",
        "description": "third_parties.lpips",
        "isExtraImport": true,
        "detail": "third_parties.lpips",
        "documentation": {}
    },
    {
        "label": "LPIPS",
        "importPath": "third_parties.lpips",
        "description": "third_parties.lpips",
        "isExtraImport": true,
        "detail": "third_parties.lpips",
        "documentation": {}
    },
    {
        "label": "create_lr_updater",
        "importPath": "core.train",
        "description": "core.train",
        "isExtraImport": true,
        "detail": "core.train",
        "documentation": {}
    },
    {
        "label": "create_trainer",
        "importPath": "core.train",
        "description": "core.train",
        "isExtraImport": true,
        "detail": "core.train",
        "documentation": {}
    },
    {
        "label": "create_optimizer",
        "importPath": "core.train",
        "description": "core.train",
        "isExtraImport": true,
        "detail": "core.train",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "core.data",
        "description": "core.data",
        "isExtraImport": true,
        "detail": "core.data",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "core.data",
        "description": "core.data",
        "isExtraImport": true,
        "detail": "core.data",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "core.data",
        "description": "core.data",
        "isExtraImport": true,
        "detail": "core.data",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "core.data",
        "description": "core.data",
        "isExtraImport": true,
        "detail": "core.data",
        "documentation": {}
    },
    {
        "label": "cpu_data_to_gpu",
        "importPath": "core.utils.train_util",
        "description": "core.utils.train_util",
        "isExtraImport": true,
        "detail": "core.utils.train_util",
        "documentation": {}
    },
    {
        "label": "Timer",
        "importPath": "core.utils.train_util",
        "description": "core.utils.train_util",
        "isExtraImport": true,
        "detail": "core.utils.train_util",
        "documentation": {}
    },
    {
        "label": "cpu_data_to_gpu",
        "importPath": "core.utils.train_util",
        "description": "core.utils.train_util",
        "isExtraImport": true,
        "detail": "core.utils.train_util",
        "documentation": {}
    },
    {
        "label": "cpu_data_to_gpu",
        "importPath": "core.utils.train_util",
        "description": "core.utils.train_util",
        "isExtraImport": true,
        "detail": "core.utils.train_util",
        "documentation": {}
    },
    {
        "label": "skimage",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "skimage",
        "description": "skimage",
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "create_network",
        "importPath": "core.nets",
        "description": "core.nets",
        "isExtraImport": true,
        "detail": "core.nets",
        "documentation": {}
    },
    {
        "label": "create_network",
        "importPath": "core.nets",
        "description": "core.nets",
        "isExtraImport": true,
        "detail": "core.nets",
        "documentation": {}
    },
    {
        "label": "create_network",
        "importPath": "core.nets",
        "description": "core.nets",
        "isExtraImport": true,
        "detail": "core.nets",
        "documentation": {}
    },
    {
        "label": "create_network",
        "importPath": "core.nets",
        "description": "core.nets",
        "isExtraImport": true,
        "detail": "core.nets",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "glob",
        "importPath": "glob",
        "description": "glob",
        "isExtraImport": true,
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "cos",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "sin",
        "importPath": "math",
        "description": "math",
        "isExtraImport": true,
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "copyfile",
        "importPath": "shutil",
        "description": "shutil",
        "isExtraImport": true,
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "copyfile",
        "importPath": "shutil",
        "description": "shutil",
        "isExtraImport": true,
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "colored",
        "importPath": "termcolor",
        "description": "termcolor",
        "isExtraImport": true,
        "detail": "termcolor",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "join",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "exists",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "dirname",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "imageio.v2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imageio.v2",
        "description": "imageio.v2",
        "detail": "imageio.v2",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "imageio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "imageio",
        "description": "imageio",
        "detail": "imageio",
        "documentation": {}
    },
    {
        "label": "SceneManager",
        "importPath": "scene_manager",
        "description": "scene_manager",
        "isExtraImport": true,
        "detail": "scene_manager",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Callable",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Sequence",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "chumpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "chumpy",
        "description": "chumpy",
        "detail": "chumpy",
        "documentation": {}
    },
    {
        "label": "Ch",
        "importPath": "chumpy",
        "description": "chumpy",
        "isExtraImport": true,
        "detail": "chumpy",
        "documentation": {}
    },
    {
        "label": "scipy.sparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.sparse",
        "description": "scipy.sparse",
        "detail": "scipy.sparse",
        "documentation": {}
    },
    {
        "label": "Capsule",
        "importPath": "capsule_ch",
        "description": "capsule_ch",
        "isExtraImport": true,
        "detail": "capsule_ch",
        "documentation": {}
    },
    {
        "label": "Rodrigues",
        "importPath": "opendr.geometry",
        "description": "opendr.geometry",
        "isExtraImport": true,
        "detail": "opendr.geometry",
        "documentation": {}
    },
    {
        "label": "scipy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy",
        "description": "scipy",
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "verts_core",
        "importPath": "smpl_webuser.lbs",
        "description": "smpl_webuser.lbs",
        "isExtraImport": true,
        "detail": "smpl_webuser.lbs",
        "documentation": {}
    },
    {
        "label": "global_rigid_transformation",
        "importPath": "smpl_webuser.lbs",
        "description": "smpl_webuser.lbs",
        "isExtraImport": true,
        "detail": "smpl_webuser.lbs",
        "documentation": {}
    },
    {
        "label": "get_capsules",
        "importPath": "capsule_body",
        "description": "capsule_body",
        "isExtraImport": true,
        "detail": "capsule_body",
        "documentation": {}
    },
    {
        "label": "set_sphere_centers",
        "importPath": "capsule_body",
        "description": "capsule_body",
        "isExtraImport": true,
        "detail": "capsule_body",
        "documentation": {}
    },
    {
        "label": "\\",
        "importPath": "capsule_body",
        "description": "capsule_body",
        "isExtraImport": true,
        "detail": "capsule_body",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "cPickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cPickle",
        "description": "cPickle",
        "detail": "cPickle",
        "documentation": {}
    },
    {
        "label": "ProjectPoints",
        "importPath": "opendr.camera",
        "description": "opendr.camera",
        "isExtraImport": true,
        "detail": "opendr.camera",
        "documentation": {}
    },
    {
        "label": "ProjectPoints",
        "importPath": "opendr.camera",
        "description": "opendr.camera",
        "isExtraImport": true,
        "detail": "opendr.camera",
        "documentation": {}
    },
    {
        "label": "GMOf",
        "importPath": "lib.robustifiers",
        "description": "lib.robustifiers",
        "isExtraImport": true,
        "detail": "lib.robustifiers",
        "documentation": {}
    },
    {
        "label": "load_model",
        "importPath": "smpl_webuser.serialization",
        "description": "smpl_webuser.serialization",
        "isExtraImport": true,
        "detail": "smpl_webuser.serialization",
        "documentation": {}
    },
    {
        "label": "verts_decorated",
        "importPath": "smpl_webuser.verts",
        "description": "smpl_webuser.verts",
        "isExtraImport": true,
        "detail": "smpl_webuser.verts",
        "documentation": {}
    },
    {
        "label": "SphereCollisions",
        "importPath": "lib.sphere_collisions",
        "description": "lib.sphere_collisions",
        "isExtraImport": true,
        "detail": "lib.sphere_collisions",
        "documentation": {}
    },
    {
        "label": "MaxMixtureCompletePrior",
        "importPath": "lib.max_mixture_prior",
        "description": "lib.max_mixture_prior",
        "isExtraImport": true,
        "detail": "lib.max_mixture_prior",
        "documentation": {}
    },
    {
        "label": "render_model",
        "importPath": "render_model",
        "description": "render_model",
        "isExtraImport": true,
        "detail": "render_model",
        "documentation": {}
    },
    {
        "label": "ColoredRenderer",
        "importPath": "opendr.renderer",
        "description": "opendr.renderer",
        "isExtraImport": true,
        "detail": "opendr.renderer",
        "documentation": {}
    },
    {
        "label": "LambertianPointLight",
        "importPath": "opendr.lighting",
        "description": "opendr.lighting",
        "isExtraImport": true,
        "detail": "opendr.lighting",
        "documentation": {}
    },
    {
        "label": "h5py",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "h5py",
        "description": "h5py",
        "detail": "h5py",
        "documentation": {}
    },
    {
        "label": "count",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "mlab",
        "importPath": "mayavi",
        "description": "mayavi",
        "isExtraImport": true,
        "detail": "mayavi",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "absolute_import",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "division",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "torch.nn.init",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.init",
        "description": "torch.nn.init",
        "detail": "torch.nn.init",
        "documentation": {}
    },
    {
        "label": "lpips",
        "importPath": "third_parties",
        "description": "third_parties",
        "isExtraImport": true,
        "detail": "third_parties",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "literal_eval",
        "importPath": "ast",
        "description": "ast",
        "isExtraImport": true,
        "detail": "ast",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "SMPL",
        "importPath": "third_parties.smpl.smpl_numpy",
        "description": "third_parties.smpl.smpl_numpy",
        "isExtraImport": true,
        "detail": "third_parties.smpl.smpl_numpy",
        "documentation": {}
    },
    {
        "label": "SMPL",
        "importPath": "third_parties.smpl.smpl_numpy",
        "description": "third_parties.smpl.smpl_numpy",
        "isExtraImport": true,
        "detail": "third_parties.smpl.smpl_numpy",
        "documentation": {}
    },
    {
        "label": "SMPL",
        "importPath": "third_parties.smpl.smpl_numpy",
        "description": "third_parties.smpl.smpl_numpy",
        "isExtraImport": true,
        "detail": "third_parties.smpl.smpl_numpy",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "flags",
        "importPath": "absl",
        "description": "absl",
        "isExtraImport": true,
        "detail": "absl",
        "documentation": {}
    },
    {
        "label": "src.utils.rotation_conversions",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.utils.rotation_conversions",
        "description": "src.utils.rotation_conversions",
        "detail": "src.utils.rotation_conversions",
        "documentation": {}
    },
    {
        "label": "get_gpu_device",
        "importPath": "src.visualize.visualize",
        "description": "src.visualize.visualize",
        "isExtraImport": true,
        "detail": "src.visualize.visualize",
        "documentation": {}
    },
    {
        "label": "load_model_wo_clip",
        "importPath": "src.utils.misc",
        "description": "src.utils.misc",
        "isExtraImport": true,
        "detail": "src.utils.misc",
        "documentation": {}
    },
    {
        "label": "src.utils.fixseed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "src.utils.fixseed",
        "description": "src.utils.fixseed",
        "detail": "src.utils.fixseed",
        "documentation": {}
    },
    {
        "label": "MatVecMult",
        "importPath": "chumpy.ch",
        "description": "chumpy.ch",
        "isExtraImport": true,
        "detail": "chumpy.ch",
        "documentation": {}
    },
    {
        "label": "MatVecMult",
        "importPath": "chumpy.ch",
        "description": "chumpy.ch",
        "isExtraImport": true,
        "detail": "chumpy.ch",
        "documentation": {}
    },
    {
        "label": "Ch",
        "importPath": "chumpy.ch",
        "description": "chumpy.ch",
        "isExtraImport": true,
        "detail": "chumpy.ch",
        "documentation": {}
    },
    {
        "label": "pyrender",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyrender",
        "description": "pyrender",
        "detail": "pyrender",
        "documentation": {}
    },
    {
        "label": "trimesh",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "trimesh",
        "description": "trimesh",
        "detail": "trimesh",
        "documentation": {}
    },
    {
        "label": "Logger",
        "importPath": "core.utils.log_util",
        "description": "core.utils.log_util",
        "isExtraImport": true,
        "detail": "core.utils.log_util",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "torch.cuda",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "torch.backends.cudnn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.backends.cudnn",
        "description": "torch.backends.cudnn",
        "detail": "torch.backends.cudnn",
        "documentation": {}
    },
    {
        "label": "Rays",
        "importPath": "datasets.utils",
        "description": "datasets.utils",
        "isExtraImport": true,
        "detail": "datasets.utils",
        "documentation": {}
    },
    {
        "label": "namedtuple_map",
        "importPath": "datasets.utils",
        "description": "datasets.utils",
        "isExtraImport": true,
        "detail": "datasets.utils",
        "documentation": {}
    },
    {
        "label": "collate",
        "importPath": "torch.utils.data._utils.collate",
        "description": "torch.utils.data._utils.collate",
        "isExtraImport": true,
        "detail": "torch.utils.data._utils.collate",
        "documentation": {}
    },
    {
        "label": "default_collate_fn_map",
        "importPath": "torch.utils.data._utils.collate",
        "description": "torch.utils.data._utils.collate",
        "isExtraImport": true,
        "detail": "torch.utils.data._utils.collate",
        "documentation": {}
    },
    {
        "label": "OccGridEstimator",
        "importPath": "nerfacc.estimators.occ_grid",
        "description": "nerfacc.estimators.occ_grid",
        "isExtraImport": true,
        "detail": "nerfacc.estimators.occ_grid",
        "documentation": {}
    },
    {
        "label": "PropNetEstimator",
        "importPath": "nerfacc.estimators.prop_net",
        "description": "nerfacc.estimators.prop_net",
        "isExtraImport": true,
        "detail": "nerfacc.estimators.prop_net",
        "documentation": {}
    },
    {
        "label": "ray_aabb_intersect",
        "importPath": "nerfacc.grid",
        "description": "nerfacc.grid",
        "isExtraImport": true,
        "detail": "nerfacc.grid",
        "documentation": {}
    },
    {
        "label": "traverse_grids",
        "importPath": "nerfacc.grid",
        "description": "nerfacc.grid",
        "isExtraImport": true,
        "detail": "nerfacc.grid",
        "documentation": {}
    },
    {
        "label": "accumulate_along_rays_",
        "importPath": "nerfacc.volrend",
        "description": "nerfacc.volrend",
        "isExtraImport": true,
        "detail": "nerfacc.volrend",
        "documentation": {}
    },
    {
        "label": "render_weight_from_density",
        "importPath": "nerfacc.volrend",
        "description": "nerfacc.volrend",
        "isExtraImport": true,
        "detail": "nerfacc.volrend",
        "documentation": {}
    },
    {
        "label": "rendering",
        "importPath": "nerfacc.volrend",
        "description": "nerfacc.volrend",
        "isExtraImport": true,
        "detail": "nerfacc.volrend",
        "documentation": {}
    },
    {
        "label": "get_cfg_defaults",
        "kind": 2,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "def get_cfg_defaults():\n    return _C.clone()\ndef parse_cfg(cfg):\n    # cfg.logdir = os.path.join('experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment)\n    cfg.logdir = os.path.join('../experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj\n    cfg.result = os.path.join('../analysis/experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj\ndef determine_primary_secondary_gpus(cfg):\n    print(\"------------------ GPU Configurations ------------------\")\n    cfg.n_gpus = torch.cuda.device_count()\n    if cfg.n_gpus > 0:",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "parse_cfg",
        "kind": 2,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "def parse_cfg(cfg):\n    # cfg.logdir = os.path.join('experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment)\n    cfg.logdir = os.path.join('../experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj\n    cfg.result = os.path.join('../analysis/experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj\ndef determine_primary_secondary_gpus(cfg):\n    print(\"------------------ GPU Configurations ------------------\")\n    cfg.n_gpus = torch.cuda.device_count()\n    if cfg.n_gpus > 0:\n        all_gpus = list(range(cfg.n_gpus))\n        cfg.primary_gpus = [0]",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "determine_primary_secondary_gpus",
        "kind": 2,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "def determine_primary_secondary_gpus(cfg):\n    print(\"------------------ GPU Configurations ------------------\")\n    cfg.n_gpus = torch.cuda.device_count()\n    if cfg.n_gpus > 0:\n        all_gpus = list(range(cfg.n_gpus))\n        cfg.primary_gpus = [0]\n        if cfg.n_gpus > 1:\n            cfg.secondary_gpus = [g for g in all_gpus \\\n                                    if g not in cfg.primary_gpus]\n        else:",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "make_cfg",
        "kind": 2,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "def make_cfg(args):\n    cfg = get_cfg_defaults()\n    cfg.merge_from_file('configs/default.yaml')\n    cfg.merge_from_file(args.cfg)\n    cfg.merge_from_list(args.opts)\n    parse_cfg(cfg)\n    determine_primary_secondary_gpus(cfg)\n    return cfg\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--cfg\", required=True, type=str)",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C = CN()\n# \"resume\" should be train options but we lift it up for cmd line convenience\n_C.resume = False\n# current iteration -- set a very large value for evaluation\n_C.eval_iter = 10000000\n# for rendering\n_C.render_folder_name = \"\"\n_C.ignore_non_rigid_motions = False\n_C.render_skip = 1\n# _C.render_frames = 100",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C.resume",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C.resume = False\n# current iteration -- set a very large value for evaluation\n_C.eval_iter = 10000000\n# for rendering\n_C.render_folder_name = \"\"\n_C.ignore_non_rigid_motions = False\n_C.render_skip = 1\n# _C.render_frames = 100\n_C.render_frames = 60 # dj\n# for data loader",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C.eval_iter",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C.eval_iter = 10000000\n# for rendering\n_C.render_folder_name = \"\"\n_C.ignore_non_rigid_motions = False\n_C.render_skip = 1\n# _C.render_frames = 100\n_C.render_frames = 60 # dj\n# for data loader\n_C.num_workers = 4  ###############\n# _C.num_workers = 1",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C.render_folder_name",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C.render_folder_name = \"\"\n_C.ignore_non_rigid_motions = False\n_C.render_skip = 1\n# _C.render_frames = 100\n_C.render_frames = 60 # dj\n# for data loader\n_C.num_workers = 4  ###############\n# _C.num_workers = 1\ndef get_cfg_defaults():\n    return _C.clone()",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C.ignore_non_rigid_motions",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C.ignore_non_rigid_motions = False\n_C.render_skip = 1\n# _C.render_frames = 100\n_C.render_frames = 60 # dj\n# for data loader\n_C.num_workers = 4  ###############\n# _C.num_workers = 1\ndef get_cfg_defaults():\n    return _C.clone()\ndef parse_cfg(cfg):",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C.render_skip",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C.render_skip = 1\n# _C.render_frames = 100\n_C.render_frames = 60 # dj\n# for data loader\n_C.num_workers = 4  ###############\n# _C.num_workers = 1\ndef get_cfg_defaults():\n    return _C.clone()\ndef parse_cfg(cfg):\n    # cfg.logdir = os.path.join('experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment)",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C.render_frames",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C.render_frames = 60 # dj\n# for data loader\n_C.num_workers = 4  ###############\n# _C.num_workers = 1\ndef get_cfg_defaults():\n    return _C.clone()\ndef parse_cfg(cfg):\n    # cfg.logdir = os.path.join('experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment)\n    cfg.logdir = os.path.join('../experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj\n    cfg.result = os.path.join('../analysis/experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "_C.num_workers",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "_C.num_workers = 4  ###############\n# _C.num_workers = 1\ndef get_cfg_defaults():\n    return _C.clone()\ndef parse_cfg(cfg):\n    # cfg.logdir = os.path.join('experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment)\n    cfg.logdir = os.path.join('../experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj\n    cfg.result = os.path.join('../analysis/experiments', cfg.category, cfg.task, cfg.subject, cfg.experiment) # dj\ndef determine_primary_secondary_gpus(cfg):\n    print(\"------------------ GPU Configurations ------------------\")",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument(\"--cfg\", required=True, type=str)\nparser.add_argument(\"--type\", default=\"skip\", type=str)\nparser.add_argument(\"opts\", default=None, nargs=argparse.REMAINDER)\nargs = parser.parse_args()\ncfg = make_cfg(args)",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "args = parser.parse_args()\ncfg = make_cfg(args)",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "cfg",
        "kind": 5,
        "importPath": "configs.config",
        "description": "configs.config",
        "peekOfCode": "cfg = make_cfg(args)",
        "detail": "configs.config",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "kind": 6,
        "importPath": "core.data.human_nerf.freeview",
        "description": "core.data.human_nerf.freeview",
        "peekOfCode": "class Dataset(torch.utils.data.Dataset):\n    ROT_CAM_PARAMS = {\n        'zju_mocap': {'rotate_axis': 'z', 'inv_angle': True},\n        'wild': {'rotate_axis': 'y', 'inv_angle': False}\n    }\n    def __init__(\n            self, \n            dataset_path,\n            keyfilter=None,\n            maxframes=-1,",
        "detail": "core.data.human_nerf.freeview",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "kind": 6,
        "importPath": "core.data.human_nerf.tpose",
        "description": "core.data.human_nerf.tpose",
        "peekOfCode": "class Dataset(torch.utils.data.Dataset):\n    RENDER_SIZE=512\n    CAM_PARAMS = {\n        'radius': 6.0, 'focal': 1250.\n    }\n    def __init__(\n            self, \n            dataset_path,\n            keyfilter=None,\n            bgcolor=None,",
        "detail": "core.data.human_nerf.tpose",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "kind": 6,
        "importPath": "core.data.human_nerf.train",
        "description": "core.data.human_nerf.train",
        "peekOfCode": "class Dataset(torch.utils.data.Dataset):\n    def __init__(self, dataset_path, keyfilter=None, maxframes=-1, bgcolor=None, ray_shoot_mode='image', skip=1, **_):\n        print('[Dataset Path]', dataset_path) \n        self.dataset_path = dataset_path\n        self.image_dir = os.path.join(dataset_path, 'images')\n        self.canonical_joints, self.canonical_bbox = self.load_canonical_joints()\n        if 'motion_weights_priors' in keyfilter:\n            self.motion_weights_priors = approx_gaussian_bone_volumes(\n                self.canonical_joints,   \n                self.canonical_bbox['min_xyz'],",
        "detail": "core.data.human_nerf.train",
        "documentation": {}
    },
    {
        "label": "create_dataset",
        "kind": 2,
        "importPath": "core.data.create_dataset",
        "description": "core.data.create_dataset",
        "peekOfCode": "def create_dataset(data_type='train'):\n    dataset_name = cfg[data_type].dataset\n    args = DatasetArgs.get(dataset_name)\n    # customize dataset arguments according to dataset type\n    args['bgcolor'] = None if data_type == 'train' else cfg.bgcolor\n    if data_type == 'progress':\n        total_train_imgs = _get_total_train_imgs(args['dataset_path'])\n        args['skip'] = total_train_imgs // 16\n        args['maxframes'] = 16\n    if data_type in ['freeview', 'tpose']:",
        "detail": "core.data.create_dataset",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "kind": 2,
        "importPath": "core.data.create_dataset",
        "description": "core.data.create_dataset",
        "peekOfCode": "def create_dataloader(data_type='train'):\n    cfg_node = cfg[data_type]\n    batch_size = cfg_node.batch_size\n    shuffle = cfg_node.shuffle\n    drop_last = cfg_node.drop_last\n    dataset = create_dataset(data_type=data_type)\n    g = torch.Generator()\n    g.manual_seed(0)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,",
        "detail": "core.data.create_dataset",
        "documentation": {}
    },
    {
        "label": "DatasetArgs",
        "kind": 6,
        "importPath": "core.data.dataset_args",
        "description": "core.data.dataset_args",
        "peekOfCode": "class DatasetArgs(object):\n    dataset_attrs = {}\n    subjects = ['313', '315', '377', '386', '387', '390', '392', '393', '394']\n    if cfg.category == 'superhumannerf' and cfg.task == 'zju_mocap': # dj\n        for sub in subjects:\n            dataset_attrs.update({\n                f\"zju_{sub}_train\": {\n                    # \"dataset_path\": f\"dataset/zju_mocap/{sub}\",\n                    \"dataset_path\": f\"../datasets/zju_mocap/{sub}\", # dj\n                    \"keyfilter\": cfg.train_keyfilter,",
        "detail": "core.data.dataset_args",
        "documentation": {}
    },
    {
        "label": "Embedder",
        "kind": 6,
        "importPath": "core.nets.human_nerf.embedders.fourier",
        "description": "core.nets.human_nerf.embedders.fourier",
        "peekOfCode": "class Embedder:\n    def __init__(self, **kwargs):\n        self.kwargs = kwargs\n        self.create_embedding_fn()\n    def create_embedding_fn(self):\n        embed_fns = []\n        d = self.kwargs['input_dims']\n        out_dim = 0\n        if self.kwargs['include_input']:\n            embed_fns.append(lambda x : x)",
        "detail": "core.nets.human_nerf.embedders.fourier",
        "documentation": {}
    },
    {
        "label": "get_embedder",
        "kind": 2,
        "importPath": "core.nets.human_nerf.embedders.fourier",
        "description": "core.nets.human_nerf.embedders.fourier",
        "peekOfCode": "def get_embedder(multires, i=0):\n    if i == -1:\n        return nn.Identity(), 3\n    embed_kwargs = {\n                'include_input' : True,\n                'input_dims' : 3,\n                'max_freq_log2' : multires-1,\n                'num_freqs' : multires,\n                'periodic_fns' : [torch.sin, torch.cos],\n    }",
        "detail": "core.nets.human_nerf.embedders.fourier",
        "documentation": {}
    },
    {
        "label": "Embedder",
        "kind": 6,
        "importPath": "core.nets.human_nerf.embedders.hannw_fourier",
        "description": "core.nets.human_nerf.embedders.hannw_fourier",
        "peekOfCode": "class Embedder:\n    def __init__(self, **kwargs):\n        self.kwargs = kwargs\n        self.create_embedding_fn()\n    def create_embedding_fn(self):\n        embed_fns = []\n        d = self.kwargs['input_dims']\n        out_dim = 0\n        if self.kwargs['include_input']:\n            embed_fns.append(lambda x : x)",
        "detail": "core.nets.human_nerf.embedders.hannw_fourier",
        "documentation": {}
    },
    {
        "label": "get_embedder",
        "kind": 2,
        "importPath": "core.nets.human_nerf.embedders.hannw_fourier",
        "description": "core.nets.human_nerf.embedders.hannw_fourier",
        "peekOfCode": "def get_embedder(multires, iter_val, is_identity=0):\n    if is_identity == -1:\n        return nn.Identity(), 3\n    embed_kwargs = {\n                'include_input' : False,\n                'input_dims' : 3,\n                'max_freq_log2' : multires-1,\n                'num_freqs' : multires,\n                'periodic_fns' : [torch.sin, torch.cos],\n                'iter_val': iter_val",
        "detail": "core.nets.human_nerf.embedders.hannw_fourier",
        "documentation": {}
    },
    {
        "label": "MotionWeightVolumeDecoder",
        "kind": 6,
        "importPath": "core.nets.human_nerf.mweight_vol_decoders.deconv_vol_decoder",
        "description": "core.nets.human_nerf.mweight_vol_decoders.deconv_vol_decoder",
        "peekOfCode": "class MotionWeightVolumeDecoder(nn.Module):\n    def __init__(self, embedding_size=256, volume_size=32, total_bones=24):\n        super(MotionWeightVolumeDecoder, self).__init__()\n        self.total_bones = total_bones\n        self.volume_size = volume_size\n        from configs import cfg\n        # torch.manual_seed(cfg.train.seed) #######################\n        self.const_embedding = nn.Parameter(torch.randn(embedding_size), requires_grad=True )\n        self.decoder = ConvDecoder3D(embedding_size=embedding_size, volume_size=volume_size, voxel_channels=total_bones+1)\n    def forward(self, motion_weights_priors, **_):",
        "detail": "core.nets.human_nerf.mweight_vol_decoders.deconv_vol_decoder",
        "documentation": {}
    },
    {
        "label": "NonRigidMotionMLP",
        "kind": 6,
        "importPath": "core.nets.human_nerf.non_rigid_motion_mlps.mlp_offset",
        "description": "core.nets.human_nerf.non_rigid_motion_mlps.mlp_offset",
        "peekOfCode": "class NonRigidMotionMLP(nn.Module):\n    def __init__(self, pos_embed_size=3, condition_code_size=69, mlp_width=128, mlp_depth=6, skips=None):\n        super(NonRigidMotionMLP, self).__init__()\n        self.skips = [4] if skips is None else skips\n        block_mlps = [nn.Linear(pos_embed_size+condition_code_size, mlp_width), nn.ReLU()]\n        layers_to_cat_inputs = []\n        for i in range(1, mlp_depth):\n            if i in self.skips:\n                layers_to_cat_inputs.append(len(block_mlps))\n                block_mlps += [nn.Linear(mlp_width+pos_embed_size, mlp_width), nn.ReLU()]",
        "detail": "core.nets.human_nerf.non_rigid_motion_mlps.mlp_offset",
        "documentation": {}
    },
    {
        "label": "BodyPoseRefiner",
        "kind": 6,
        "importPath": "core.nets.human_nerf.pose_decoders.mlp_delta_body_pose",
        "description": "core.nets.human_nerf.pose_decoders.mlp_delta_body_pose",
        "peekOfCode": "class BodyPoseRefiner(nn.Module):\n    def __init__(self,\n                 embedding_size=69,\n                 mlp_width=256,\n                 mlp_depth=4,\n                 **_):\n        super(BodyPoseRefiner, self).__init__()\n        # breakpoint()\n        # embedding_size: 69; mlp_width: 256; mlp_depth: 4\n        block_mlps = [nn.Linear(embedding_size, mlp_width), nn.ReLU()]",
        "detail": "core.nets.human_nerf.pose_decoders.mlp_delta_body_pose",
        "documentation": {}
    },
    {
        "label": "_src_path",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.backend",
        "description": "core.nets.human_nerf.raymarching.backend",
        "peekOfCode": "_src_path = os.path.dirname(os.path.abspath(__file__))\nnvcc_flags = [\n    '-O3', '-std=c++14',\n    '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_HALF2_OPERATORS__',\n]\nif os.name == \"posix\":\n    c_flags = ['-O3', '-std=c++14']\nelif os.name == \"nt\":\n    c_flags = ['/O2', '/std:c++17']\n    # find cl.exe",
        "detail": "core.nets.human_nerf.raymarching.backend",
        "documentation": {}
    },
    {
        "label": "nvcc_flags",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.backend",
        "description": "core.nets.human_nerf.raymarching.backend",
        "peekOfCode": "nvcc_flags = [\n    '-O3', '-std=c++14',\n    '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_HALF2_OPERATORS__',\n]\nif os.name == \"posix\":\n    c_flags = ['-O3', '-std=c++14']\nelif os.name == \"nt\":\n    c_flags = ['/O2', '/std:c++17']\n    # find cl.exe\n    def find_cl_path():",
        "detail": "core.nets.human_nerf.raymarching.backend",
        "documentation": {}
    },
    {
        "label": "_backend",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.backend",
        "description": "core.nets.human_nerf.raymarching.backend",
        "peekOfCode": "_backend = load(name='_raymarching',\n                extra_cflags=c_flags,\n                extra_cuda_cflags=nvcc_flags,\n                sources=[os.path.join(_src_path, 'src', f) for f in [\n                    'raymarching.cu',\n                    'bindings.cpp',\n                ]],\n                )\n__all__ = ['_backend']",
        "detail": "core.nets.human_nerf.raymarching.backend",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.backend",
        "description": "core.nets.human_nerf.raymarching.backend",
        "peekOfCode": "__all__ = ['_backend']",
        "detail": "core.nets.human_nerf.raymarching.backend",
        "documentation": {}
    },
    {
        "label": "_near_far_from_aabb",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _near_far_from_aabb(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, rays_o, rays_d, aabb, min_near=0.2):\n        ''' near_far_from_aabb, CUDA implementation\n        Calculate rays' intersection time (near and far) with aabb\n        Args:\n            rays_o: float, [N, 3]\n            rays_d: float, [N, 3]\n            aabb: float, [6], (xmin, ymin, zmin, xmax, ymax, zmax)",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_sph_from_ray",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _sph_from_ray(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, rays_o, rays_d, radius):\n        ''' sph_from_ray, CUDA implementation\n        get spherical coordinate on the background sphere from rays.\n        Assume rays_o are inside the Sphere(radius).\n        Args:\n            rays_o: [N, 3]\n            rays_d: [N, 3]",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_morton3D",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _morton3D(Function):\n    @staticmethod\n    def forward(ctx, coords):\n        ''' morton3D, CUDA implementation\n        Args:\n            coords: [N, 3], int32, in [0, 128) (for some reason there is no uint32 tensor in torch...) \n            TODO: check if the coord range is valid! (current 128 is safe)\n        Returns:\n            indices: [N], int32, in [0, 128^3)\n        '''",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_morton3D_invert",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _morton3D_invert(Function):\n    @staticmethod\n    def forward(ctx, indices):\n        ''' morton3D_invert, CUDA implementation\n        Args:\n            indices: [N], int32, in [0, 128^3)\n        Returns:\n            coords: [N, 3], int32, in [0, 128)\n        '''\n        if not indices.is_cuda: indices = indices.cuda()",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_packbits",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _packbits(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, grid, thresh, bitfield=None):\n        ''' packbits, CUDA implementation\n        Pack up the density grid into a bit field to accelerate ray marching.\n        Args:\n            grid: float, [C, H * H * H], assume H % 2 == 0\n            thresh: float, threshold\n        Returns:",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_march_rays_train",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _march_rays_train(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, rays_o, rays_d, bound, density_bitfield, C, H, nears, fars, step_counter=None, mean_count=-1, perturb=False, align=-1, force_all_rays=False, dt_gamma=0, max_steps=1024):\n        ''' march rays to generate points (forward only)\n        Args:\n            rays_o/d: float, [N, 3]\n            bound: float, scalar\n            density_bitfield: uint8: [CHHH // 8]   # density_bitfield is used for point sampling\n            C: int",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_composite_rays_train",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _composite_rays_train(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, sigmas, rgbs, deltas, rays, T_thresh=1e-4):\n        ''' composite rays' rgbs, according to the ray marching formula.\n        Args:\n            rgbs: float, [M, 3]\n            sigmas: float, [M,]\n            deltas: float, [M, 2]\n            rays: int32, [N, 3]",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_march_rays",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _march_rays(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, n_alive, n_step, rays_alive, rays_t, rays_o, rays_d, bound, density_bitfield, C, H, near, far, align=-1, perturb=False, dt_gamma=0, max_steps=1024):\n        ''' march rays to generate points (forward only, for inference)\n        Args:\n            n_alive: int, number of alive rays\n            n_step: int, how many steps we march\n            rays_alive: int, [N], the alive rays' IDs in N (N >= n_alive, but we only use first n_alive)\n            rays_t: float, [N], the alive rays' time, we only use the first n_alive.",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_composite_rays",
        "kind": 6,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "class _composite_rays(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32) # need to cast sigmas & rgbs to float\n    def forward(ctx, n_alive, n_step, rays_alive, rays_t, sigmas, rgbs, deltas, weights_sum, depth, image, T_thresh=1e-2):\n        ''' composite rays' rgbs, according to the ray marching formula. (for inference)\n        Args:\n            n_alive: int, number of alive rays\n            n_step: int, how many steps we march\n            rays_alive: int, [n_alive], the alive rays' IDs in N (N >= n_alive)\n            rays_t: float, [N], the alive rays' time",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "near_far_from_aabb",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "near_far_from_aabb = _near_far_from_aabb.apply\nclass _sph_from_ray(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, rays_o, rays_d, radius):\n        ''' sph_from_ray, CUDA implementation\n        get spherical coordinate on the background sphere from rays.\n        Assume rays_o are inside the Sphere(radius).\n        Args:\n            rays_o: [N, 3]",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "sph_from_ray",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "sph_from_ray = _sph_from_ray.apply\nclass _morton3D(Function):\n    @staticmethod\n    def forward(ctx, coords):\n        ''' morton3D, CUDA implementation\n        Args:\n            coords: [N, 3], int32, in [0, 128) (for some reason there is no uint32 tensor in torch...) \n            TODO: check if the coord range is valid! (current 128 is safe)\n        Returns:\n            indices: [N], int32, in [0, 128^3)",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "morton3D",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "morton3D = _morton3D.apply\nclass _morton3D_invert(Function):\n    @staticmethod\n    def forward(ctx, indices):\n        ''' morton3D_invert, CUDA implementation\n        Args:\n            indices: [N], int32, in [0, 128^3)\n        Returns:\n            coords: [N, 3], int32, in [0, 128)\n        '''",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "morton3D_invert",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "morton3D_invert = _morton3D_invert.apply\nclass _packbits(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, grid, thresh, bitfield=None):\n        ''' packbits, CUDA implementation\n        Pack up the density grid into a bit field to accelerate ray marching.\n        Args:\n            grid: float, [C, H * H * H], assume H % 2 == 0\n            thresh: float, threshold",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "packbits",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "packbits = _packbits.apply\n# ----------------------------------------\n# train functions\n# ----------------------------------------\nclass _march_rays_train(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, rays_o, rays_d, bound, density_bitfield, C, H, nears, fars, step_counter=None, mean_count=-1, perturb=False, align=-1, force_all_rays=False, dt_gamma=0, max_steps=1024):\n        ''' march rays to generate points (forward only)\n        Args:",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "march_rays_train",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "march_rays_train = _march_rays_train.apply\nclass _composite_rays_train(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, sigmas, rgbs, deltas, rays, T_thresh=1e-4):\n        ''' composite rays' rgbs, according to the ray marching formula.\n        Args:\n            rgbs: float, [M, 3]\n            sigmas: float, [M,]\n            deltas: float, [M, 2]",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "composite_rays_train",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "composite_rays_train = _composite_rays_train.apply\n# ----------------------------------------\n# infer functions\n# ----------------------------------------\nclass _march_rays(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, n_alive, n_step, rays_alive, rays_t, rays_o, rays_d, bound, density_bitfield, C, H, near, far, align=-1, perturb=False, dt_gamma=0, max_steps=1024):\n        ''' march rays to generate points (forward only, for inference)\n        Args:",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "march_rays",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "march_rays = _march_rays.apply\nclass _composite_rays(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32) # need to cast sigmas & rgbs to float\n    def forward(ctx, n_alive, n_step, rays_alive, rays_t, sigmas, rgbs, deltas, weights_sum, depth, image, T_thresh=1e-2):\n        ''' composite rays' rgbs, according to the ray marching formula. (for inference)\n        Args:\n            n_alive: int, number of alive rays\n            n_step: int, how many steps we march\n            rays_alive: int, [n_alive], the alive rays' IDs in N (N >= n_alive)",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "composite_rays",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.raymarching",
        "description": "core.nets.human_nerf.raymarching.raymarching",
        "peekOfCode": "composite_rays = _composite_rays.apply",
        "detail": "core.nets.human_nerf.raymarching.raymarching",
        "documentation": {}
    },
    {
        "label": "_src_path",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.setup",
        "description": "core.nets.human_nerf.raymarching.setup",
        "peekOfCode": "_src_path = os.path.dirname(os.path.abspath(__file__))\nnvcc_flags = [\n    '-O3', '-std=c++14',\n    '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_HALF2_OPERATORS__',\n]\nif os.name == \"posix\":\n    c_flags = ['-O3', '-std=c++14']\nelif os.name == \"nt\":\n    c_flags = ['/O2', '/std:c++17']\n    # find cl.exe",
        "detail": "core.nets.human_nerf.raymarching.setup",
        "documentation": {}
    },
    {
        "label": "nvcc_flags",
        "kind": 5,
        "importPath": "core.nets.human_nerf.raymarching.setup",
        "description": "core.nets.human_nerf.raymarching.setup",
        "peekOfCode": "nvcc_flags = [\n    '-O3', '-std=c++14',\n    '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_HALF2_OPERATORS__',\n]\nif os.name == \"posix\":\n    c_flags = ['-O3', '-std=c++14']\nelif os.name == \"nt\":\n    c_flags = ['/O2', '/std:c++17']\n    # find cl.exe\n    def find_cl_path():",
        "detail": "core.nets.human_nerf.raymarching.setup",
        "documentation": {}
    },
    {
        "label": "_trunc_exp",
        "kind": 6,
        "importPath": "core.nets.human_nerf.activation",
        "description": "core.nets.human_nerf.activation",
        "peekOfCode": "class _trunc_exp(Function):\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32) # cast to float32\n    def forward(ctx, x):\n        ctx.save_for_backward(x)\n        return torch.exp(x)\n    @staticmethod\n    @custom_bwd\n    def backward(ctx, g):\n        x = ctx.saved_tensors[0]",
        "detail": "core.nets.human_nerf.activation",
        "documentation": {}
    },
    {
        "label": "trunc_exp",
        "kind": 5,
        "importPath": "core.nets.human_nerf.activation",
        "description": "core.nets.human_nerf.activation",
        "peekOfCode": "trunc_exp = _trunc_exp.apply",
        "detail": "core.nets.human_nerf.activation",
        "documentation": {}
    },
    {
        "label": "load_positional_embedder",
        "kind": 2,
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "peekOfCode": "def load_positional_embedder(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    # print(module_path) (core/nets/human_nerf/embedders/hannw_fourier.py)\n    return imp.load_source(module, module_path).get_embedder\ndef load_canonical_mlp(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    return imp.load_source(module, module_path).CanonicalMLP\ndef load_mweight_vol_decoder(module_name):",
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_canonical_mlp",
        "kind": 2,
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "peekOfCode": "def load_canonical_mlp(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    return imp.load_source(module, module_path).CanonicalMLP\ndef load_mweight_vol_decoder(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    # print(module_path) (core/nets/human_nerf/mweight_vol_decoders/deconv_vol_decoder.py)\n    return imp.load_source(module, module_path).MotionWeightVolumeDecoder\ndef load_pose_decoder(module_name):",
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_mweight_vol_decoder",
        "kind": 2,
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "peekOfCode": "def load_mweight_vol_decoder(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    # print(module_path) (core/nets/human_nerf/mweight_vol_decoders/deconv_vol_decoder.py)\n    return imp.load_source(module, module_path).MotionWeightVolumeDecoder\ndef load_pose_decoder(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    # print(module_path) (core/nets/human_nerf/pose_decoders/mlp_delta_body_pose.py)\n    return imp.load_source(module, module_path).BodyPoseRefiner",
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_pose_decoder",
        "kind": 2,
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "peekOfCode": "def load_pose_decoder(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    # print(module_path) (core/nets/human_nerf/pose_decoders/mlp_delta_body_pose.py)\n    return imp.load_source(module, module_path).BodyPoseRefiner\ndef load_non_rigid_motion_mlp(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    # print(module_path) (core/nets/human_nerf/non_rigid_motion_mlps/mlp_offset.py)\n    return imp.load_source(module, module_path).NonRigidMotionMLP",
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "load_non_rigid_motion_mlp",
        "kind": 2,
        "importPath": "core.nets.human_nerf.component_factory",
        "description": "core.nets.human_nerf.component_factory",
        "peekOfCode": "def load_non_rigid_motion_mlp(module_name):\n    module = module_name\n    module_path = module.replace(\".\", \"/\") + \".py\"\n    # print(module_path) (core/nets/human_nerf/non_rigid_motion_mlps/mlp_offset.py)\n    return imp.load_source(module, module_path).NonRigidMotionMLP",
        "detail": "core.nets.human_nerf.component_factory",
        "documentation": {}
    },
    {
        "label": "Network",
        "kind": 6,
        "importPath": "core.nets.human_nerf.network",
        "description": "core.nets.human_nerf.network",
        "peekOfCode": "class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        # Skeletal motion ----------------------------------------------\n        # motion basis computer\n        self.motion_basis_computer = MotionBasisComputer(total_bones=cfg.total_bones)\n        # motion weight volume\n        self.mweight_vol_decoder = load_mweight_vol_decoder(cfg.mweight_volume.module)(\n            embedding_size=cfg.mweight_volume.embedding_size,\n            volume_size=cfg.mweight_volume.volume_size,",
        "detail": "core.nets.human_nerf.network",
        "documentation": {}
    },
    {
        "label": "create_network",
        "kind": 2,
        "importPath": "core.nets.create_network",
        "description": "core.nets.create_network",
        "peekOfCode": "def create_network():\n    network = _query_network()\n    network = network()\n    return network",
        "detail": "core.nets.create_network",
        "documentation": {}
    },
    {
        "label": "get_customized_lr_names",
        "kind": 2,
        "importPath": "core.train.optimizers.human_nerf.optimizer",
        "description": "core.train.optimizers.human_nerf.optimizer",
        "peekOfCode": "def get_customized_lr_names():\n    return [k[3:] for k in cfg.train.keys() if k.startswith('lr_')]\ndef get_optimizer(network):\n    optimizer = _optimizers[cfg.train.optimizer]\n    cus_lr_names = get_customized_lr_names()\n    params = []\n    print('\\n\\n********** learnable parameters **********\\n')\n    for key, value in network.named_parameters():\n        if not value.requires_grad:\n            continue",
        "detail": "core.train.optimizers.human_nerf.optimizer",
        "documentation": {}
    },
    {
        "label": "get_optimizer",
        "kind": 2,
        "importPath": "core.train.optimizers.human_nerf.optimizer",
        "description": "core.train.optimizers.human_nerf.optimizer",
        "peekOfCode": "def get_optimizer(network):\n    optimizer = _optimizers[cfg.train.optimizer]\n    cus_lr_names = get_customized_lr_names()\n    params = []\n    print('\\n\\n********** learnable parameters **********\\n')\n    for key, value in network.named_parameters():\n        if not value.requires_grad:\n            continue\n        is_assigned_lr = False\n        for lr_name in cus_lr_names:",
        "detail": "core.train.optimizers.human_nerf.optimizer",
        "documentation": {}
    },
    {
        "label": "_optimizers",
        "kind": 5,
        "importPath": "core.train.optimizers.human_nerf.optimizer",
        "description": "core.train.optimizers.human_nerf.optimizer",
        "peekOfCode": "_optimizers = {\n    'adam': optim.Adam\n}\ndef get_customized_lr_names():\n    return [k[3:] for k in cfg.train.keys() if k.startswith('lr_')]\ndef get_optimizer(network):\n    optimizer = _optimizers[cfg.train.optimizer]\n    cus_lr_names = get_customized_lr_names()\n    params = []\n    print('\\n\\n********** learnable parameters **********\\n')",
        "detail": "core.train.optimizers.human_nerf.optimizer",
        "documentation": {}
    },
    {
        "label": "get_customized_lr_names",
        "kind": 2,
        "importPath": "core.train.trainers.human_nerf.lr_updaters.exp_decay",
        "description": "core.train.trainers.human_nerf.lr_updaters.exp_decay",
        "peekOfCode": "def get_customized_lr_names():\n    return [k[3:] for k in cfg.train.keys() if k.startswith('lr_')]\ndef update_lr(optimizer, iter_step):\n    decay_rate = 0.1\n    decay_steps = cfg.train.lrate_decay * 1000\n    decay_value = decay_rate ** (iter_step / decay_steps)\n    for param_group in optimizer.param_groups:\n        if f\"lr_{param_group['name']}\" in cfg.train:\n            base_lr = cfg.train[f\"lr_{param_group['name']}\"]\n            new_lrate = base_lr * decay_value",
        "detail": "core.train.trainers.human_nerf.lr_updaters.exp_decay",
        "documentation": {}
    },
    {
        "label": "update_lr",
        "kind": 2,
        "importPath": "core.train.trainers.human_nerf.lr_updaters.exp_decay",
        "description": "core.train.trainers.human_nerf.lr_updaters.exp_decay",
        "peekOfCode": "def update_lr(optimizer, iter_step):\n    decay_rate = 0.1\n    decay_steps = cfg.train.lrate_decay * 1000\n    decay_value = decay_rate ** (iter_step / decay_steps)\n    for param_group in optimizer.param_groups:\n        if f\"lr_{param_group['name']}\" in cfg.train:\n            base_lr = cfg.train[f\"lr_{param_group['name']}\"]\n            new_lrate = base_lr * decay_value\n        else:\n            new_lrate = cfg.train.lr * decay_value",
        "detail": "core.train.trainers.human_nerf.lr_updaters.exp_decay",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "kind": 6,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "class Trainer(object):\n    def __init__(self, network, optimizer):\n        print('\\n********** Init Trainer ***********')\n        network = network.cuda().deploy_mlps_to_secondary_gpus()\n        self.network = network\n        self.optimizer = optimizer\n        self.update_lr = create_lr_updater()\n        if cfg.resume and Trainer.ckpt_exists(cfg.load_net):\n            self.load_ckpt(f'{cfg.load_net}')\n        else:",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "scale_for_lpips",
        "kind": 2,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "def scale_for_lpips(image_tensor):\n    return image_tensor * 2. - 1.\nclass Trainer(object):\n    def __init__(self, network, optimizer):\n        print('\\n********** Init Trainer ***********')\n        network = network.cuda().deploy_mlps_to_secondary_gpus()\n        self.network = network\n        self.optimizer = optimizer\n        self.update_lr = create_lr_updater()\n        if cfg.resume and Trainer.ckpt_exists(cfg.load_net):",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "img2mse",
        "kind": 5,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "img2mse = lambda x, y : torch.mean((x - y) ** 2)\nimg2l1 = lambda x, y : torch.mean(torch.abs(x-y))\nmse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.]).to(x.device)) \n# to8b = lambda x : (255.*np.clip(x,0.,1.)).astype(np.uint8)\nmse_np = lambda x, y : np.mean((x - y) ** 2)                                             \nmse2psnr_np = lambda x : -10. * np.log(x) / np.log(10.)                                  \nEXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask', 'framelist']\ndef _unpack_imgs(rgbs, patch_masks, bgcolor, targets, div_indices):\n    N_patch = len(div_indices) - 1\n    assert patch_masks.shape[0] == N_patch",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "img2l1",
        "kind": 5,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "img2l1 = lambda x, y : torch.mean(torch.abs(x-y))\nmse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.]).to(x.device)) \n# to8b = lambda x : (255.*np.clip(x,0.,1.)).astype(np.uint8)\nmse_np = lambda x, y : np.mean((x - y) ** 2)                                             \nmse2psnr_np = lambda x : -10. * np.log(x) / np.log(10.)                                  \nEXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask', 'framelist']\ndef _unpack_imgs(rgbs, patch_masks, bgcolor, targets, div_indices):\n    N_patch = len(div_indices) - 1\n    assert patch_masks.shape[0] == N_patch\n    assert targets.shape[0] == N_patch",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "mse2psnr",
        "kind": 5,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "mse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.]).to(x.device)) \n# to8b = lambda x : (255.*np.clip(x,0.,1.)).astype(np.uint8)\nmse_np = lambda x, y : np.mean((x - y) ** 2)                                             \nmse2psnr_np = lambda x : -10. * np.log(x) / np.log(10.)                                  \nEXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask', 'framelist']\ndef _unpack_imgs(rgbs, patch_masks, bgcolor, targets, div_indices):\n    N_patch = len(div_indices) - 1\n    assert patch_masks.shape[0] == N_patch\n    assert targets.shape[0] == N_patch\n    patch_imgs = bgcolor.expand(targets.shape).clone() # (N_patch, H, W, 3)",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "mse_np",
        "kind": 5,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "mse_np = lambda x, y : np.mean((x - y) ** 2)                                             \nmse2psnr_np = lambda x : -10. * np.log(x) / np.log(10.)                                  \nEXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask', 'framelist']\ndef _unpack_imgs(rgbs, patch_masks, bgcolor, targets, div_indices):\n    N_patch = len(div_indices) - 1\n    assert patch_masks.shape[0] == N_patch\n    assert targets.shape[0] == N_patch\n    patch_imgs = bgcolor.expand(targets.shape).clone() # (N_patch, H, W, 3)\n    for i in range(N_patch):\n        patch_imgs[i, patch_masks[i]] = rgbs[div_indices[i]:div_indices[i+1]]",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "mse2psnr_np",
        "kind": 5,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "mse2psnr_np = lambda x : -10. * np.log(x) / np.log(10.)                                  \nEXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask', 'framelist']\ndef _unpack_imgs(rgbs, patch_masks, bgcolor, targets, div_indices):\n    N_patch = len(div_indices) - 1\n    assert patch_masks.shape[0] == N_patch\n    assert targets.shape[0] == N_patch\n    patch_imgs = bgcolor.expand(targets.shape).clone() # (N_patch, H, W, 3)\n    for i in range(N_patch):\n        patch_imgs[i, patch_masks[i]] = rgbs[div_indices[i]:div_indices[i+1]]\n    return patch_imgs",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "EXCLUDE_KEYS_TO_GPU",
        "kind": 5,
        "importPath": "core.train.trainers.human_nerf.trainer",
        "description": "core.train.trainers.human_nerf.trainer",
        "peekOfCode": "EXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask', 'framelist']\ndef _unpack_imgs(rgbs, patch_masks, bgcolor, targets, div_indices):\n    N_patch = len(div_indices) - 1\n    assert patch_masks.shape[0] == N_patch\n    assert targets.shape[0] == N_patch\n    patch_imgs = bgcolor.expand(targets.shape).clone() # (N_patch, H, W, 3)\n    for i in range(N_patch):\n        patch_imgs[i, patch_masks[i]] = rgbs[div_indices[i]:div_indices[i+1]]\n    return patch_imgs\ndef _unpack_alpha(alphas, patch_masks, div_indices):",
        "detail": "core.train.trainers.human_nerf.trainer",
        "documentation": {}
    },
    {
        "label": "create_lr_updater",
        "kind": 2,
        "importPath": "core.train.create_lr_updater",
        "description": "core.train.create_lr_updater",
        "peekOfCode": "def create_lr_updater():\n    module = cfg.lr_updater_module\n    lr_updater_path = module.replace(\".\", \"/\") + \".py\"\n    return imp.load_source(module, lr_updater_path).update_lr",
        "detail": "core.train.create_lr_updater",
        "documentation": {}
    },
    {
        "label": "create_optimizer",
        "kind": 2,
        "importPath": "core.train.create_optimizer",
        "description": "core.train.create_optimizer",
        "peekOfCode": "def create_optimizer(network):\n    module = cfg.optimizer_module\n    optimizer_path = module.replace(\".\", \"/\") + \".py\"\n    return imp.load_source(module, optimizer_path).get_optimizer(network)",
        "detail": "core.train.create_optimizer",
        "documentation": {}
    },
    {
        "label": "create_trainer",
        "kind": 2,
        "importPath": "core.train.create_trainer",
        "description": "core.train.create_trainer",
        "peekOfCode": "def create_trainer(network, optimizer):\n    Trainer = _query_trainer()\n    return Trainer(network, optimizer)",
        "detail": "core.train.create_trainer",
        "documentation": {}
    },
    {
        "label": "body_pose_to_body_RTs",
        "kind": 2,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "def body_pose_to_body_RTs(jangles, tpose_joints):\n    r\"\"\" Convert body pose to global rotation matrix R and translation T.\n    Args:\n        - jangles (joint angles): Array (Total_Joints x 3, )\n        - tpose_joints:           Array (Total_Joints, 3)\n    Returns:\n        - Rs: Array (Total_Joints, 3, 3)\n        - Ts: Array (Total_Joints, 3)\n    \"\"\"\n    jangles = jangles.reshape(-1, 3)",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "get_canonical_global_tfms",
        "kind": 2,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "def get_canonical_global_tfms(canonical_joints):\n    r\"\"\" Convert canonical joints to 4x4 global transformation matrix.\n    Args:\n        - canonical_joints: Array (Total_Joints, 3)\n    Returns:\n        - Array (Total_Joints, 4, 4)\n    \"\"\"\n    total_bones = canonical_joints.shape[0]\n    gtfms = np.zeros(shape=(total_bones, 4, 4), dtype='float32')\n    gtfms[0] = _construct_G(np.eye(3), canonical_joints[0,:])",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "approx_gaussian_bone_volumes",
        "kind": 2,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "def approx_gaussian_bone_volumes(\n    tpose_joints, \n    bbox_min_xyz, bbox_max_xyz,\n    grid_size=32):\n    r\"\"\" Compute approximated Gaussian bone volume.\n    Args:\n        - tpose_joints:  Array (Total_Joints, 3)\n        - bbox_min_xyz:  Array (3, )\n        - bbox_max_xyz:  Array (3, )\n        - grid_size:     Integer",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "SMPL_JOINT_IDX",
        "kind": 5,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "SMPL_JOINT_IDX = {\n    'pelvis_root': 0,\n    'left_hip': 1,\n    'right_hip': 2,\n    'belly_button': 3,\n    'left_knee': 4,\n    'right_knee': 5,\n    'lower_chest': 6,\n    'left_ankle': 7,\n    'right_ankle': 8,",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "SMPL_PARENT",
        "kind": 5,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "SMPL_PARENT = {\n    1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 3, 7: 4, 8: 5, 9: 6, 10: 7, \n    11: 8, 12: 9, 13: 9, 14: 9, 15: 12, 16: 13, 17: 14, 18: 16, 19: 17, 20: 18, \n    21: 19, 22: 20, 23: 21}\nTORSO_JOINTS_NAME = [\n    'pelvis_root', 'belly_button', 'lower_chest', 'upper_chest', 'left_clavicle', 'right_clavicle'\n]\nTORSO_JOINTS = [\n    SMPL_JOINT_IDX[joint_name] for joint_name in TORSO_JOINTS_NAME\n]",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "TORSO_JOINTS_NAME",
        "kind": 5,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "TORSO_JOINTS_NAME = [\n    'pelvis_root', 'belly_button', 'lower_chest', 'upper_chest', 'left_clavicle', 'right_clavicle'\n]\nTORSO_JOINTS = [\n    SMPL_JOINT_IDX[joint_name] for joint_name in TORSO_JOINTS_NAME\n]\nBONE_STDS = np.array([0.03, 0.06, 0.03])\nHEAD_STDS = np.array([0.06, 0.06, 0.06])\nJOINT_STDS = np.array([0.02, 0.02, 0.02])\ndef _to_skew_matrix(v):",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "TORSO_JOINTS",
        "kind": 5,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "TORSO_JOINTS = [\n    SMPL_JOINT_IDX[joint_name] for joint_name in TORSO_JOINTS_NAME\n]\nBONE_STDS = np.array([0.03, 0.06, 0.03])\nHEAD_STDS = np.array([0.06, 0.06, 0.06])\nJOINT_STDS = np.array([0.02, 0.02, 0.02])\ndef _to_skew_matrix(v):\n    r\"\"\" Compute the skew matrix given a 3D vectors.\n    Args:\n        - v: Array (3, )",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "BONE_STDS",
        "kind": 5,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "BONE_STDS = np.array([0.03, 0.06, 0.03])\nHEAD_STDS = np.array([0.06, 0.06, 0.06])\nJOINT_STDS = np.array([0.02, 0.02, 0.02])\ndef _to_skew_matrix(v):\n    r\"\"\" Compute the skew matrix given a 3D vectors.\n    Args:\n        - v: Array (3, )\n    Returns:\n        - Array (3, 3)\n    \"\"\"",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "HEAD_STDS",
        "kind": 5,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "HEAD_STDS = np.array([0.06, 0.06, 0.06])\nJOINT_STDS = np.array([0.02, 0.02, 0.02])\ndef _to_skew_matrix(v):\n    r\"\"\" Compute the skew matrix given a 3D vectors.\n    Args:\n        - v: Array (3, )\n    Returns:\n        - Array (3, 3)\n    \"\"\"\n    vx, vy, vz = v.ravel()",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "JOINT_STDS",
        "kind": 5,
        "importPath": "core.utils.body_util",
        "description": "core.utils.body_util",
        "peekOfCode": "JOINT_STDS = np.array([0.02, 0.02, 0.02])\ndef _to_skew_matrix(v):\n    r\"\"\" Compute the skew matrix given a 3D vectors.\n    Args:\n        - v: Array (3, )\n    Returns:\n        - Array (3, 3)\n    \"\"\"\n    vx, vy, vz = v.ravel()\n    return np.array([[0, -vz, vy],",
        "detail": "core.utils.body_util",
        "documentation": {}
    },
    {
        "label": "get_camrot",
        "kind": 2,
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "peekOfCode": "def get_camrot(campos, lookat=None, inv_camera=False):\n    r\"\"\" Compute rotation part of extrinsic matrix from camera posistion and\n         where it looks at.\n    Args:\n        - campos: Array (3, )\n        - lookat: Array (3, )\n        - inv_camera: Boolean\n    Returns:\n        - Array (3, 3)\n    Reference: http://ksimek.github.io/2012/08/22/extrinsic/",
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "rotate_camera_by_frame_idx",
        "kind": 2,
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "peekOfCode": "def rotate_camera_by_frame_idx(\n        extrinsics, \n        frame_idx, \n        trans=None,\n        rotate_axis='y',\n        period=196,\n        inv_angle=False):\n    r\"\"\" Get camera extrinsics based on frame index and rotation period.\n    Args:\n        - extrinsics: Array (3, 3)",
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "apply_global_tfm_to_camera",
        "kind": 2,
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "peekOfCode": "def apply_global_tfm_to_camera(E, Rh, Th):\n    r\"\"\" Get camera extrinsics that considers global transformation.\n    Args:\n        - E: Array (3, 3)\n        - Rh: Array (3, )\n        - Th: Array (3, )\n    Returns:\n        - Array (3, 3)\n    \"\"\"\n    global_tfms = np.eye(4)  #(4, 4)",
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "get_rays_from_KRT",
        "kind": 2,
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "peekOfCode": "def get_rays_from_KRT(H, W, K, R, T):\n    r\"\"\" Sample rays on an image based on camera matrices (K, R and T)\n    Args:\n        - H: Integer\n        - W: Integer\n        - K: Array (3, 3)\n        - R: Array (3, 3)\n        - T: Array (3, )\n    Returns:\n        - rays_o: Array (H, W, 3)",
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "rays_intersect_3d_bbox",
        "kind": 2,
        "importPath": "core.utils.camera_util",
        "description": "core.utils.camera_util",
        "peekOfCode": "def rays_intersect_3d_bbox(bounds, ray_o, ray_d):\n    r\"\"\"calculate intersections with 3d bounding box\n        Args:\n            - bounds: dictionary or list\n            - ray_o: (N_rays, 3)\n            - ray_d, (N_rays, 3)\n        Output:\n            - near: (N_VALID_RAYS, )\n            - far: (N_VALID_RAYS, )\n            - mask_at_box: (N_RAYS, )",
        "detail": "core.utils.camera_util",
        "documentation": {}
    },
    {
        "label": "list_files",
        "kind": 2,
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "peekOfCode": "def list_files(folder_path, exts=None, keyword=None):\n    file_list = [\n            os.path.join(folder_path, fname)\n            for fname in os.listdir(folder_path)\n                if os.path.isfile(os.path.join(folder_path, fname))\n                    and (exts is None or any(fname.endswith(ext) for ext in exts))\n                    and (keyword is None or (fname.find(keyword)!=-1))\n        ]\n    file_list = sorted(file_list)\n    return file_list",
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "split_path",
        "kind": 2,
        "importPath": "core.utils.file_util",
        "description": "core.utils.file_util",
        "peekOfCode": "def split_path(file_path):\n    file_dir, file_name = os.path.split(file_path)\n    file_base_name, file_ext = os.path.splitext(file_name)\n    return file_dir, file_base_name, file_ext",
        "detail": "core.utils.file_util",
        "documentation": {}
    },
    {
        "label": "ImageWriter",
        "kind": 6,
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "peekOfCode": "class ImageWriter():\n    def __init__(self, output_dir, exp_name):\n        self.image_dir = os.path.join(output_dir, exp_name)\n        print(\"The rendering is saved in \" + \\\n              colored(self.image_dir, 'cyan'))\n        # remove image dir if it exists\n        if os.path.exists(self.image_dir):\n            shutil.rmtree(self.image_dir)\n        os.makedirs(self.image_dir, exist_ok=True)\n        self.frame_idx = -1",
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "load_image",
        "kind": 2,
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "peekOfCode": "def load_image(path, to_rgb=True):\n    img = Image.open(path)\n    return img.convert('RGB') if to_rgb else img\ndef save_image(image_numpy, image_path):\n    image_pil = Image.fromarray(image_numpy)\n    image_pil.save(image_path)\ndef to_8b_image(image):\n    return (255.* np.clip(image, 0., 1.)).astype(np.uint8)\ndef to_3ch_image(image):\n    if len(image.shape) == 2:",
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "save_image",
        "kind": 2,
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "peekOfCode": "def save_image(image_numpy, image_path):\n    image_pil = Image.fromarray(image_numpy)\n    image_pil.save(image_path)\ndef to_8b_image(image):\n    return (255.* np.clip(image, 0., 1.)).astype(np.uint8)\ndef to_3ch_image(image):\n    if len(image.shape) == 2:\n        return np.stack([image, image, image], axis=-1)\n    elif len(image.shape) == 3:\n        assert image.shape[2] == 1",
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b_image",
        "kind": 2,
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "peekOfCode": "def to_8b_image(image):\n    return (255.* np.clip(image, 0., 1.)).astype(np.uint8)\ndef to_3ch_image(image):\n    if len(image.shape) == 2:\n        return np.stack([image, image, image], axis=-1)\n    elif len(image.shape) == 3:\n        assert image.shape[2] == 1\n        return np.concatenate([image, image, image], axis=-1)\n    else:\n        print(f\"to_3ch_image: Unsupported Shapes: {len(image.shape)}\")",
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_3ch_image",
        "kind": 2,
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "peekOfCode": "def to_3ch_image(image):\n    if len(image.shape) == 2:\n        return np.stack([image, image, image], axis=-1)\n    elif len(image.shape) == 3:\n        assert image.shape[2] == 1\n        return np.concatenate([image, image, image], axis=-1)\n    else:\n        print(f\"to_3ch_image: Unsupported Shapes: {len(image.shape)}\")\n        return image\ndef to_8b3ch_image(image):",
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "to_8b3ch_image",
        "kind": 2,
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "peekOfCode": "def to_8b3ch_image(image):\n    return to_3ch_image(to_8b_image(image))\ndef tile_images(images, imgs_per_row=4):\n    rows = []\n    row = []\n    imgs_per_row = min(len(images), imgs_per_row)\n    for i in range(len(images)):\n        row.append(images[i])\n        if len(row) == imgs_per_row:\n            rows.append(np.concatenate(row, axis=1))",
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "tile_images",
        "kind": 2,
        "importPath": "core.utils.image_util",
        "description": "core.utils.image_util",
        "peekOfCode": "def tile_images(images, imgs_per_row=4):\n    rows = []\n    row = []\n    imgs_per_row = min(len(images), imgs_per_row)\n    for i in range(len(images)):\n        row.append(images[i])\n        if len(row) == imgs_per_row:\n            rows.append(np.concatenate(row, axis=1))\n            row = []\n    if len(rows) > 2 and len(rows[-1]) != len(rows[-2]):",
        "detail": "core.utils.image_util",
        "documentation": {}
    },
    {
        "label": "Logger",
        "kind": 6,
        "importPath": "core.utils.log_util",
        "description": "core.utils.log_util",
        "peekOfCode": "class Logger(object):\n    r\"\"\"Duplicates all stdout to a file.\"\"\"\n    def __init__(self):\n        path = os.path.join(cfg.logdir, 'logs.txt')\n        log_dir = cfg.logdir\n        if not cfg.resume and os.path.exists(log_dir):\n            user_input = input(f\"log dir \\\"{log_dir}\\\" exists. \\nRemove? (y/n):\")\n            if user_input == 'y':\n                print(colored('remove contents of directory %s' % log_dir, 'red'))\n                os.system('rm -r %s/*' % log_dir)",
        "detail": "core.utils.log_util",
        "documentation": {}
    },
    {
        "label": "ConvDecoder3D",
        "kind": 6,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "class ConvDecoder3D(nn.Module):\n    r\"\"\" Convolutional 3D volume decoder.\"\"\"\n    def __init__(self, embedding_size=256, volume_size=128, voxel_channels=4):\n        r\"\"\" \n            Args:\n                embedding_size: integer\n                volume_size: integer\n                voxel_channels: integer\n        \"\"\"    \n        super(ConvDecoder3D, self).__init__()",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "RodriguesModule",
        "kind": 6,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "class RodriguesModule(nn.Module):\n    def forward(self, rvec):\n        r''' Apply Rodriguez formula on a batch of rotation vectors.\n            Args:\n                rvec: Tensor (B, 3)\n            Returns\n                rmtx: Tensor (B, 3, 3)\n        '''\n        theta = torch.sqrt(1e-5 + torch.sum(rvec ** 2, dim=1))\n        rvec = rvec / theta[:, None]",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "MotionBasisComputer",
        "kind": 6,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "class MotionBasisComputer(nn.Module):\n    r\"\"\"Compute motion bases between the target pose and canonical pose.\"\"\"\n    def __init__(self, total_bones=24):\n        super(MotionBasisComputer, self).__init__()\n        self.total_bones = total_bones\n    def _construct_G(self, R_mtx, T):\n        r''' Tile ration matrix and translation vector to build a 4x4 matrix.\n        Args:\n            R_mtx: Tensor (B, TOTAL_BONES, 3, 3)\n            T:     Tensor (B, TOTAL_BONES, 3)",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "xaviermultiplier",
        "kind": 2,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "def xaviermultiplier(m, gain):\n    \"\"\" \n        Args:\n            m (torch.nn.Module)\n            gain (float)\n        Returns:\n            std (float): adjusted standard deviation\n    \"\"\" \n    if isinstance(m, nn.Conv1d):\n        ksize = m.kernel_size[0]",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "xavier_uniform_",
        "kind": 2,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "def xavier_uniform_(m, gain):\n    \"\"\" Set module weight values with a uniform distribution.\n        Args:\n            m (torch.nn.Module)\n            gain (float)\n    \"\"\" \n    std = xaviermultiplier(m, gain)\n    m.weight.data.uniform_(-(std * math.sqrt(3.0)), std * math.sqrt(3.0))\ndef initmod(m, gain=1.0, weightinitfunc=xavier_uniform_):\n    \"\"\" Initialized module weights.",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "initmod",
        "kind": 2,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "def initmod(m, gain=1.0, weightinitfunc=xavier_uniform_):\n    \"\"\" Initialized module weights.\n        Args:\n            m (torch.nn.Module)\n            gain (float)\n            weightinitfunc (function)\n    \"\"\" \n    validclasses = [nn.Linear, nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.ConvTranspose1d, nn.ConvTranspose2d, nn.ConvTranspose3d]\n    if any([isinstance(m, x) for x in validclasses]):\n        weightinitfunc(m, gain)",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "initseq",
        "kind": 2,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "def initseq(s):\n    \"\"\" Initialized weights of all modules in a module sequence.\n        Args:\n            s (torch.nn.Sequential)\n    \"\"\" \n    for a, b in zip(s[:-1], s[1:]):\n        if isinstance(b, nn.ReLU):\n            initmod(a, nn.init.calculate_gain('relu'))\n        elif isinstance(b, nn.LeakyReLU):\n            initmod(a, nn.init.calculate_gain('leaky_relu', b.negative_slope))",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "set_requires_grad",
        "kind": 2,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "def set_requires_grad(nets, requires_grad=False):\n    if not isinstance(nets, list):\n        nets = [nets]\n    for net in nets:\n        if net is not None:\n            for param in net.parameters():\n                param.requires_grad = requires_grad",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "SMPL_PARENT",
        "kind": 5,
        "importPath": "core.utils.network_util",
        "description": "core.utils.network_util",
        "peekOfCode": "SMPL_PARENT = {\n    1: 0, 2: 0, 3: 0, 4: 1, 5: 2, 6: 3, 7: 4, 8: 5, 9: 6, 10: 7, \n    11: 8, 12: 9, 13: 9, 14: 9, 15: 12, 16: 13, 17: 14, 18: 16, 19: 17, 20: 18, \n    21: 19, 22: 20, 23: 21\n}\nclass MotionBasisComputer(nn.Module):\n    r\"\"\"Compute motion bases between the target pose and canonical pose.\"\"\"\n    def __init__(self, total_bones=24):\n        super(MotionBasisComputer, self).__init__()\n        self.total_bones = total_bones",
        "detail": "core.utils.network_util",
        "documentation": {}
    },
    {
        "label": "Timer",
        "kind": 6,
        "importPath": "core.utils.train_util",
        "description": "core.utils.train_util",
        "peekOfCode": "class Timer():\n    def __init__(self):\n        self.curr_time = 0\n    def begin(self):\n        self.curr_time = time.time()\n    def log(self):\n        diff_time = time.time() - self.curr_time\n        self.begin()\n        return f\"{diff_time:.2f} sec\"",
        "detail": "core.utils.train_util",
        "documentation": {}
    },
    {
        "label": "cpu_data_to_gpu",
        "kind": 2,
        "importPath": "core.utils.train_util",
        "description": "core.utils.train_util",
        "peekOfCode": "def cpu_data_to_gpu(cpu_data, exclude_keys=None):\n    if exclude_keys is None:\n        exclude_keys = []\n    gpu_data = {}\n    for key, val in cpu_data.items():\n        if key in exclude_keys:\n            continue\n        if isinstance(val, list):\n            assert len(val) > 0\n            if not isinstance(val[0], str):",
        "detail": "core.utils.train_util",
        "documentation": {}
    },
    {
        "label": "ROOT_DIR",
        "kind": 5,
        "importPath": "csrc.setup",
        "description": "csrc.setup",
        "peekOfCode": "ROOT_DIR = osp.dirname(osp.abspath(__file__))\ninclude_dirs = [osp.join(ROOT_DIR, \"include\")]\n# \"helper_math.h\" is copied from https://github.com/NVIDIA/cuda-samples/blob/master/Common/helper_math.h\nsources = glob.glob('*.cpp')+glob.glob('*.cu')\nsetup(\n    name='vren',\n    version='2.0',\n    author='kwea123',\n    author_email='kwea123@gmail.com',\n    description='cuda volume rendering library',",
        "detail": "csrc.setup",
        "documentation": {}
    },
    {
        "label": "include_dirs",
        "kind": 5,
        "importPath": "csrc.setup",
        "description": "csrc.setup",
        "peekOfCode": "include_dirs = [osp.join(ROOT_DIR, \"include\")]\n# \"helper_math.h\" is copied from https://github.com/NVIDIA/cuda-samples/blob/master/Common/helper_math.h\nsources = glob.glob('*.cpp')+glob.glob('*.cu')\nsetup(\n    name='vren',\n    version='2.0',\n    author='kwea123',\n    author_email='kwea123@gmail.com',\n    description='cuda volume rendering library',\n    long_description='cuda volume rendering library',",
        "detail": "csrc.setup",
        "documentation": {}
    },
    {
        "label": "sources",
        "kind": 5,
        "importPath": "csrc.setup",
        "description": "csrc.setup",
        "peekOfCode": "sources = glob.glob('*.cpp')+glob.glob('*.cu')\nsetup(\n    name='vren',\n    version='2.0',\n    author='kwea123',\n    author_email='kwea123@gmail.com',\n    description='cuda volume rendering library',\n    long_description='cuda volume rendering library',\n    ext_modules=[\n        CUDAExtension(",
        "detail": "csrc.setup",
        "documentation": {}
    },
    {
        "label": "SubjectLoader",
        "kind": 6,
        "importPath": "datasets.dnerf_synthetic",
        "description": "datasets.dnerf_synthetic",
        "peekOfCode": "class SubjectLoader(torch.utils.data.Dataset):\n    \"\"\"Single subject data loader for training and evaluation.\"\"\"\n    SPLITS = [\"train\", \"val\", \"test\"]\n    SUBJECT_IDS = [\n        \"bouncingballs\",\n        \"hellwarrior\",\n        \"hook\",\n        \"jumpingjacks\",\n        \"lego\",\n        \"mutant\",",
        "detail": "datasets.dnerf_synthetic",
        "documentation": {}
    },
    {
        "label": "SubjectLoader",
        "kind": 6,
        "importPath": "datasets.nerf_360_v2",
        "description": "datasets.nerf_360_v2",
        "peekOfCode": "class SubjectLoader(torch.utils.data.Dataset):\n    \"\"\"Single subject data loader for training and evaluation.\"\"\"\n    SPLITS = [\"train\", \"test\"]\n    SUBJECT_IDS = [\n        \"garden\",\n        \"bicycle\",\n        \"bonsai\",\n        \"counter\",\n        \"kitchen\",\n        \"room\",",
        "detail": "datasets.nerf_360_v2",
        "documentation": {}
    },
    {
        "label": "similarity_from_cameras",
        "kind": 2,
        "importPath": "datasets.nerf_360_v2",
        "description": "datasets.nerf_360_v2",
        "peekOfCode": "def similarity_from_cameras(c2w, strict_scaling):\n    \"\"\"\n    reference: nerf-factory\n    Get a similarity transform to normalize dataset\n    from c2w (OpenCV convention) cameras\n    :param c2w: (N, 4)\n    :return T (4,4) , scale (float)\n    \"\"\"\n    t = c2w[:, :3, 3]\n    R = c2w[:, :3, :3]",
        "detail": "datasets.nerf_360_v2",
        "documentation": {}
    },
    {
        "label": "_PATH",
        "kind": 5,
        "importPath": "datasets.nerf_360_v2",
        "description": "datasets.nerf_360_v2",
        "peekOfCode": "_PATH = os.path.abspath(__file__)\nsys.path.insert(\n    0, os.path.join(os.path.dirname(_PATH), \"..\", \"pycolmap\", \"pycolmap\")\n)\nfrom scene_manager import SceneManager\ndef _load_colmap(root_fp: str, subject_id: str, factor: int = 1):\n    assert factor in [1, 2, 4, 8]\n    data_dir = os.path.join(root_fp, subject_id)\n    colmap_dir = os.path.join(data_dir, \"sparse/0/\")\n    manager = SceneManager(colmap_dir)",
        "detail": "datasets.nerf_360_v2",
        "documentation": {}
    },
    {
        "label": "SubjectLoader",
        "kind": 6,
        "importPath": "datasets.nerf_synthetic",
        "description": "datasets.nerf_synthetic",
        "peekOfCode": "class SubjectLoader(torch.utils.data.Dataset):\n    \"\"\"Single subject data loader for training and evaluation.\"\"\"\n    SPLITS = [\"train\", \"val\", \"trainval\", \"test\"]\n    SUBJECT_IDS = [\n        \"chair\",\n        \"drums\",\n        \"ficus\",\n        \"hotdog\",\n        \"lego\",\n        \"materials\",",
        "detail": "datasets.nerf_synthetic",
        "documentation": {}
    },
    {
        "label": "namedtuple_map",
        "kind": 2,
        "importPath": "datasets.utils",
        "description": "datasets.utils",
        "peekOfCode": "def namedtuple_map(fn, tup):\n    \"\"\"Apply `fn` to each element of `tup` and cast to `tup`'s namedtuple.\"\"\"\n    return type(tup)(*(None if x is None else fn(x) for x in tup))",
        "detail": "datasets.utils",
        "documentation": {}
    },
    {
        "label": "Rays",
        "kind": 5,
        "importPath": "datasets.utils",
        "description": "datasets.utils",
        "peekOfCode": "Rays = collections.namedtuple(\"Rays\", (\"origins\", \"viewdirs\"))\ndef namedtuple_map(fn, tup):\n    \"\"\"Apply `fn` to each element of `tup` and cast to `tup`'s namedtuple.\"\"\"\n    return type(tup)(*(None if x is None else fn(x) for x in tup))",
        "detail": "datasets.utils",
        "documentation": {}
    },
    {
        "label": "MLP",
        "kind": 6,
        "importPath": "radiance_fields.mlp",
        "description": "radiance_fields.mlp",
        "peekOfCode": "class MLP(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,  # The number of input tensor channels.\n        output_dim: int = None,  # The number of output tensor channels.\n        net_depth: int = 8,  # The depth of the MLP.\n        net_width: int = 256,  # The width of the MLP.\n        skip_layer: int = 4,  # The layer to add skip layers to.\n        hidden_init: Callable = nn.init.xavier_uniform_,\n        hidden_activation: Callable = nn.ReLU(),",
        "detail": "radiance_fields.mlp",
        "documentation": {}
    },
    {
        "label": "DenseLayer",
        "kind": 6,
        "importPath": "radiance_fields.mlp",
        "description": "radiance_fields.mlp",
        "peekOfCode": "class DenseLayer(MLP):\n    def __init__(self, input_dim, output_dim, **kwargs):\n        super().__init__(\n            input_dim=input_dim,\n            output_dim=output_dim,\n            net_depth=0,  # no hidden layers\n            **kwargs,\n        )\nclass NerfMLP(nn.Module):\n    def __init__(",
        "detail": "radiance_fields.mlp",
        "documentation": {}
    },
    {
        "label": "NerfMLP",
        "kind": 6,
        "importPath": "radiance_fields.mlp",
        "description": "radiance_fields.mlp",
        "peekOfCode": "class NerfMLP(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,  # The number of input tensor channels.\n        condition_dim: int,  # The number of condition tensor channels.\n        net_depth: int = 8,  # The depth of the MLP.\n        net_width: int = 256,  # The width of the MLP.\n        skip_layer: int = 4,  # The layer to add skip layers to.\n        net_depth_condition: int = 1,  # The depth of the second part of MLP.\n        net_width_condition: int = 128,  # The width of the second part of MLP.",
        "detail": "radiance_fields.mlp",
        "documentation": {}
    },
    {
        "label": "SinusoidalEncoder",
        "kind": 6,
        "importPath": "radiance_fields.mlp",
        "description": "radiance_fields.mlp",
        "peekOfCode": "class SinusoidalEncoder(nn.Module):\n    \"\"\"Sinusoidal Positional Encoder used in Nerf.\"\"\"\n    def __init__(self, x_dim, min_deg, max_deg, use_identity: bool = True):\n        super().__init__()\n        self.x_dim = x_dim\n        self.min_deg = min_deg\n        self.max_deg = max_deg\n        self.use_identity = use_identity\n        self.register_buffer(\n            \"scales\", torch.tensor([2**i for i in range(min_deg, max_deg)])",
        "detail": "radiance_fields.mlp",
        "documentation": {}
    },
    {
        "label": "VanillaNeRFRadianceField",
        "kind": 6,
        "importPath": "radiance_fields.mlp",
        "description": "radiance_fields.mlp",
        "peekOfCode": "class VanillaNeRFRadianceField(nn.Module):\n    def __init__(\n        self,\n        net_depth: int = 8,  # The depth of the MLP.\n        net_width: int = 256,  # The width of the MLP.\n        skip_layer: int = 4,  # The layer to add skip layers to.\n        net_depth_condition: int = 1,  # The depth of the second part of MLP.\n        net_width_condition: int = 128,  # The width of the second part of MLP.\n    ) -> None:\n        super().__init__()",
        "detail": "radiance_fields.mlp",
        "documentation": {}
    },
    {
        "label": "TNeRFRadianceField",
        "kind": 6,
        "importPath": "radiance_fields.mlp",
        "description": "radiance_fields.mlp",
        "peekOfCode": "class TNeRFRadianceField(nn.Module):\n    def __init__(self) -> None:\n        super().__init__()\n        self.posi_encoder = SinusoidalEncoder(3, 0, 4, True)\n        self.time_encoder = SinusoidalEncoder(1, 0, 4, True)\n        self.warp = MLP(\n            input_dim=self.posi_encoder.latent_dim\n            + self.time_encoder.latent_dim,\n            output_dim=3,\n            net_depth=4,",
        "detail": "radiance_fields.mlp",
        "documentation": {}
    },
    {
        "label": "NDRTNeRFRadianceField",
        "kind": 6,
        "importPath": "radiance_fields.mlp",
        "description": "radiance_fields.mlp",
        "peekOfCode": "class NDRTNeRFRadianceField(nn.Module):\n    \"\"\"Invertble NN from https://arxiv.org/pdf/2206.15258.pdf\"\"\"\n    def __init__(self) -> None:\n        super().__init__()\n        self.time_encoder = SinusoidalEncoder(1, 0, 4, True)\n        self.warp_layers_1 = nn.ModuleList()\n        self.time_layers_1 = nn.ModuleList()\n        self.warp_layers_2 = nn.ModuleList()\n        self.time_layers_2 = nn.ModuleList()\n        self.posi_encoder_1 = SinusoidalEncoder(2, 0, 4, True)",
        "detail": "radiance_fields.mlp",
        "documentation": {}
    },
    {
        "label": "_TruncExp",
        "kind": 6,
        "importPath": "radiance_fields.ngp",
        "description": "radiance_fields.ngp",
        "peekOfCode": "class _TruncExp(Function):  # pylint: disable=abstract-method\n    # Implementation from torch-ngp:\n    # https://github.com/ashawkey/torch-ngp/blob/93b08a0d4ec1cc6e69d85df7f0acdfb99603b628/activation.py\n    @staticmethod\n    @custom_fwd(cast_inputs=torch.float32)\n    def forward(ctx, x):  # pylint: disable=arguments-differ\n        ctx.save_for_backward(x)\n        return torch.exp(x)\n    @staticmethod\n    @custom_bwd",
        "detail": "radiance_fields.ngp",
        "documentation": {}
    },
    {
        "label": "NGPRadianceField",
        "kind": 6,
        "importPath": "radiance_fields.ngp",
        "description": "radiance_fields.ngp",
        "peekOfCode": "class NGPRadianceField(torch.nn.Module):\n    \"\"\"Instance-NGP Radiance Field\"\"\"\n    def __init__(\n        self,\n        aabb: Union[torch.Tensor, List[float]],\n        num_dim: int = 3,\n        use_viewdirs: bool = True,\n        density_activation: Callable = lambda x: trunc_exp(x - 1),\n        unbounded: bool = False,\n        base_resolution: int = 16,",
        "detail": "radiance_fields.ngp",
        "documentation": {}
    },
    {
        "label": "NGPDensityField",
        "kind": 6,
        "importPath": "radiance_fields.ngp",
        "description": "radiance_fields.ngp",
        "peekOfCode": "class NGPDensityField(torch.nn.Module):\n    \"\"\"Instance-NGP Density Field used for resampling\"\"\"\n    def __init__(\n        self,\n        aabb: Union[torch.Tensor, List[float]],\n        num_dim: int = 3,\n        density_activation: Callable = lambda x: trunc_exp(x - 1),\n        unbounded: bool = False,\n        base_resolution: int = 16,\n        max_resolution: int = 128,",
        "detail": "radiance_fields.ngp",
        "documentation": {}
    },
    {
        "label": "contract_to_unisphere",
        "kind": 2,
        "importPath": "radiance_fields.ngp",
        "description": "radiance_fields.ngp",
        "peekOfCode": "def contract_to_unisphere(\n    x: torch.Tensor,\n    aabb: torch.Tensor,\n    ord: Union[str, int] = 2,\n    #  ord: Union[float, int] = float(\"inf\"),\n    eps: float = 1e-6,\n    derivative: bool = False,\n):\n    aabb_min, aabb_max = torch.split(aabb, 3, dim=-1)\n    x = (x - aabb_min) / (aabb_max - aabb_min)",
        "detail": "radiance_fields.ngp",
        "documentation": {}
    },
    {
        "label": "trunc_exp",
        "kind": 5,
        "importPath": "radiance_fields.ngp",
        "description": "radiance_fields.ngp",
        "peekOfCode": "trunc_exp = _TruncExp.apply\ndef contract_to_unisphere(\n    x: torch.Tensor,\n    aabb: torch.Tensor,\n    ord: Union[str, int] = 2,\n    #  ord: Union[float, int] = float(\"inf\"),\n    eps: float = 1e-6,\n    derivative: bool = False,\n):\n    aabb_min, aabb_max = torch.split(aabb, 3, dim=-1)",
        "detail": "radiance_fields.ngp",
        "documentation": {}
    },
    {
        "label": "load_network",
        "kind": 2,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "def load_network():\n    model = create_network()\n    ckpt_path = os.path.join(cfg.logdir, f'{cfg.load_net}.tar')\n    ckpt = torch.load(ckpt_path, map_location='cuda:0')\n    model.load_state_dict(ckpt['network'], strict=False)\n    print('load network from ', ckpt_path)\n    return model.cuda().deploy_mlps_to_secondary_gpus()\ndef unpack_alpha_map(alpha_vals, ray_mask, width, height):\n    alpha_map = np.zeros((height * width), dtype='float32')\n    alpha_map[ray_mask] = alpha_vals",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "unpack_alpha_map",
        "kind": 2,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "def unpack_alpha_map(alpha_vals, ray_mask, width, height):\n    alpha_map = np.zeros((height * width), dtype='float32')\n    alpha_map[ray_mask] = alpha_vals\n    return alpha_map.reshape((height, width))\ndef unpack_to_image(width, height, ray_mask, bgcolor,\n                    rgb, alpha, truth=None):\n    rgb_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    truth_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    rgb_image[ray_mask] = rgb\n    rgb_image = to_8b_image(rgb_image.reshape((height, width, 3)))",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "unpack_to_image",
        "kind": 2,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "def unpack_to_image(width, height, ray_mask, bgcolor,\n                    rgb, alpha, truth=None):\n    rgb_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    truth_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    rgb_image[ray_mask] = rgb\n    rgb_image = to_8b_image(rgb_image.reshape((height, width, 3)))\n    if truth is not None:\n        truth_image[ray_mask] = truth\n        truth_image = to_8b_image(truth_image.reshape((height, width, 3)))\n    alpha_map = unpack_alpha_map(alpha, ray_mask, width, height)",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "run_freeview",
        "kind": 2,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "def run_freeview():\n    _freeview(\n        data_type='freeview',\n        folder_name=f\"freeview_{cfg.freeview.frame_idx}\" \\\n            if not cfg.render_folder_name else cfg.render_folder_name)\ndef run_tpose():\n    cfg.ignore_non_rigid_motions = True\n    _freeview(\n        data_type='tpose',\n        folder_name='tpose' \\",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "run_tpose",
        "kind": 2,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "def run_tpose():\n    cfg.ignore_non_rigid_motions = True\n    _freeview(\n        data_type='tpose',\n        folder_name='tpose' \\\n            if not cfg.render_folder_name else cfg.render_folder_name)\ndef run_movement(render_folder_name='movement'):\n    cfg.perturb = 0.\n    model = load_network()\n    # breakpoint()",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "run_movement",
        "kind": 2,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "def run_movement(render_folder_name='movement'):\n    cfg.perturb = 0.\n    model = load_network()\n    # breakpoint()\n    test_loader = create_dataloader('movement')\n    writer = ImageWriter(\n        output_dir=os.path.join(cfg.logdir, cfg.load_net),\n        exp_name=render_folder_name)\n    model.eval()\n    for idx, batch in enumerate(tqdm(test_loader)):",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "EXCLUDE_KEYS_TO_GPU",
        "kind": 5,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "EXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask']\ncfg.bgcolor = [200,200,200] # dj \n# cfg.show_alpha = True # dj\ndef load_network():\n    model = create_network()\n    ckpt_path = os.path.join(cfg.logdir, f'{cfg.load_net}.tar')\n    ckpt = torch.load(ckpt_path, map_location='cuda:0')\n    model.load_state_dict(ckpt['network'], strict=False)\n    print('load network from ', ckpt_path)\n    return model.cuda().deploy_mlps_to_secondary_gpus()",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "cfg.bgcolor",
        "kind": 5,
        "importPath": "scripts.run.run",
        "description": "scripts.run.run",
        "peekOfCode": "cfg.bgcolor = [200,200,200] # dj \n# cfg.show_alpha = True # dj\ndef load_network():\n    model = create_network()\n    ckpt_path = os.path.join(cfg.logdir, f'{cfg.load_net}.tar')\n    ckpt = torch.load(ckpt_path, map_location='cuda:0')\n    model.load_state_dict(ckpt['network'], strict=False)\n    print('load network from ', ckpt_path)\n    return model.cuda().deploy_mlps_to_secondary_gpus()\ndef unpack_alpha_map(alpha_vals, ray_mask, width, height):",
        "detail": "scripts.run.run",
        "documentation": {}
    },
    {
        "label": "get_capsules",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "def get_capsules(model, wrt_betas=None, length_regs=None, rad_regs=None):\n    from opendr.geometry import Rodrigues\n    if length_regs is not None:\n        n_shape_dofs = length_regs.shape[0] - 1\n    else:\n        n_shape_dofs = model.betas.r.size\n    segm = np.argmax(model.weights_prior, axis=1)\n    J_off = ch.zeros((len(joint2name), 3))\n    rots = rots0.copy()\n    mujoco_t_mid = [0, 3, 6, 9]",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "set_sphere_centers",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "def set_sphere_centers(capsule, floor=True):\n    if floor:\n        n_spheres = int(np.floor(capsule.length.r / (2 * capsule.rad.r) - 1))\n    else:\n        n_spheres = int(np.ceil(capsule.length.r / (2 * capsule.rad.r) - 1))\n    # remove \"redundant\" spheres for right and left thigh...\n    if capsule.id == 1 or capsule.id == 2:\n        centers = [capsule.axis[1].r]\n    # ... and right and left upper arm\n    elif capsule.id == 14 or capsule.id == 15:",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "capsule_dist",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "def capsule_dist(capsule0, capsule1, alpha=.3, increase_hand=True):\n    range0 = range(capsule0.center_id,\n                   capsule0.center_id + len(capsule0.centers))\n    range1 = range(capsule1.center_id,\n                   capsule1.center_id + len(capsule1.centers))\n    cnt0 = ch.concatenate([[cid] * len(range1) for cid in range0])\n    cnt1 = ch.concatenate([range1] * len(range0))\n    if increase_hand:\n        if (capsule0.id == 18) or (capsule0.id == 19) or (\n                capsule1.id == 18) or (capsule1.id == 19):",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "get_capsule_bweights",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "def get_capsule_bweights(vs):\n    # \"blend\" weights for the capsule. They are binary\n    rows = np.arange(vs.shape[0])\n    cols = np.tile(np.hstack((range(10), range(12, 22))), (52, 1)).T.ravel()\n    data = np.ones(vs.shape[0])\n    caps_weights = np.asarray(\n        sp.csc_matrix(\n            (data, (rows, cols)), shape=(vs.shape[0], 24)).todense())\n    return caps_weights\ndef get_sphere_bweights(sph_vs, capsules):",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "get_sphere_bweights",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "def get_sphere_bweights(sph_vs, capsules):\n    rows = np.arange(sph_vs.shape[0])\n    cols = []\n    for cps, w in zip(capsules, range(10) + range(12, 22)):\n        cols.append([w] * len(cps.centers))\n    cols = np.hstack(cols)\n    data = np.ones(sph_vs.shape[0])\n    sph_weights = np.asarray(\n        sp.csc_matrix(\n            (data, (rows, cols)), shape=(sph_vs.shape[0], 24)).todense())",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "joint2name",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "joint2name = ['pelvis', 'leftThigh', 'rightThigh', 'spine', 'leftCalf',\n              'rightCalf', 'spine1', 'leftFoot', 'rightFoot', 'spine2', 'neck',\n              'leftShoulder', 'rightShoulder', 'head', 'leftUpperArm',\n              'rightUpperArm', 'leftForeArm', 'rightForeArm', 'leftHand',\n              'rightHand']\n# the orientation of each capsule\nrots0 = ch.asarray(\n    [[0, 0, np.pi / 2], [0, 0, np.pi], [0, 0, np.pi], [0, 0, np.pi / 2],\n     [0, 0, np.pi], [0, 0, np.pi], [0, 0, np.pi / 2], [np.pi / 2, 0, 0],\n     [np.pi / 2, 0, 0], [0, 0, np.pi / 2], [0, 0, 0], [0, 0, -np.pi / 2],",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "rots0",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "rots0 = ch.asarray(\n    [[0, 0, np.pi / 2], [0, 0, np.pi], [0, 0, np.pi], [0, 0, np.pi / 2],\n     [0, 0, np.pi], [0, 0, np.pi], [0, 0, np.pi / 2], [np.pi / 2, 0, 0],\n     [np.pi / 2, 0, 0], [0, 0, np.pi / 2], [0, 0, 0], [0, 0, -np.pi / 2],\n     [0, 0, np.pi / 2], [0, 0, 0], [0, 0, -np.pi / 2], [0, 0, np.pi / 2],\n     [0, 0, -np.pi / 2], [0, 0, np.pi / 2], [0, 0, -np.pi / 2],\n     [0, 0, np.pi / 2]])\n# groups hands and fingers, feet and toes\n# each comment line provides the body part corresonding to the capsule\n# and the corresponding id",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "mujoco2segm",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "mujoco2segm = [[0],  # hip 0\n               [1],  # leftThigh 1\n               [2],  # rightThigh 2\n               [3],  # spine 3\n               [4],  # leftCalf 4\n               [5],  # rightCalf 5\n               [6],  # spine1 6\n               [7, 10],  # leftFoot + leftToes 7\n               [8, 11],  # rightFoot + rightToes 8\n               [9],  # spine2 9",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "collisions",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_body",
        "description": "smplify.smplify_public.code.lib.capsule_body",
        "peekOfCode": "collisions = [\n    [0, 16],  # hip and leftForeArm\n    [0, 17],  # hip and rightForeArm\n    [0, 18],  # hip and leftHand\n    [0, 19],  # hip and rightHand\n    [3, 16],  # spine and leftForeArm\n    [3, 17],  # spine and rightForeArm\n    [3, 18],  # spine and leftHand\n    [3, 19],  # spine and rightHand\n    [4, 5],  # leftCalf and rightCalf",
        "detail": "smplify.smplify_public.code.lib.capsule_body",
        "documentation": {}
    },
    {
        "label": "Capsule",
        "kind": 6,
        "importPath": "smplify.smplify_public.code.lib.capsule_ch",
        "description": "smplify.smplify_public.code.lib.capsule_ch",
        "peekOfCode": "class Capsule(object):\n    def __init__(self, t, rod, rad, length):\n        assert (hasattr(t, 'dterms'))\n        # the translation should be a chumpy object (differentiable wrt shape)\n        self.t = t  # translation of the axis\n        self.rod = rod  # rotation of the axis in Rodrigues form\n        # the radius should be a chumpy object (differentiable wrt shape)\n        assert (hasattr(rad, 'dterms'))\n        self.rad = rad  # radius of the capsule\n        # the length should be a chumpy object (differentiable wrt shape)",
        "detail": "smplify.smplify_public.code.lib.capsule_ch",
        "documentation": {}
    },
    {
        "label": "cap_f",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_ch",
        "description": "smplify.smplify_public.code.lib.capsule_ch",
        "peekOfCode": "cap_f = np.asarray(\n    [[0, 7, 6], [1, 7, 9], [0, 6, 11], [0, 11, 13], [0, 13, 10], [1, 9, 16],\n     [2, 8, 18], [3, 12, 20], [4, 14, 22], [5, 15, 24], [1, 16, 19],\n     [2, 18, 21], [3, 20, 23], [4, 22, 25], [5, 24, 17], [16, 17, 26],\n     [22, 23, 32], [48, 18, 28], [49, 20, 30], [24, 25, 34], [25, 22, 50],\n     [28, 19, 47], [30, 21, 48], [32, 23, 49], [17, 24, 51], [26, 17, 51],\n     [34, 25, 50], [23, 20, 49], [21, 18, 48], [19, 16, 47], [51, 24, 34],\n     [24, 15, 25], [15, 4, 25], [50, 22, 32], [22, 14, 23], [14, 3, 23],\n     [20, 21, 30], [20, 12, 21], [12, 2, 21], [18, 19, 28], [18, 8, 19],\n     [8, 1, 19], [47, 16, 26], [16, 9, 17], [9, 5, 17], [10, 15, 5],",
        "detail": "smplify.smplify_public.code.lib.capsule_ch",
        "documentation": {}
    },
    {
        "label": "elev",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_ch",
        "description": "smplify.smplify_public.code.lib.capsule_ch",
        "peekOfCode": "elev = np.asarray(\n    [0., 0.5535673, 1.01721871, 0., -1.01721871, -0.5535673, 0.52359324,\n     0.31415301, 0.94246863, 0., -0.31415301, 0., 0.52359547, -0.52359324,\n     -0.52359547, -0.94246863, 0.31415501, -0.31415501, 1.57079633, 0.94247719,\n     0.31415501, 0.94247719, -0.94247719, -0.31415501, -0.94247719,\n     -1.57079633, -0.31415624, 0., 0.94248124, 1.01722122, 0.94247396,\n     0.55356579, -0.31415377, -0.55356579, -1.57079233, -1.01722122,\n     0.52359706, 0.94246791, 0., -0.94246791, -0.52359706, 0.52359371, 0., 0.,\n     0.31415246, -0.31415246, -0.52359371, 0.31415624, 1.57079233, 0.31415377,\n     -0.94247396, -0.94248124])",
        "detail": "smplify.smplify_public.code.lib.capsule_ch",
        "documentation": {}
    },
    {
        "label": "az",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_ch",
        "description": "smplify.smplify_public.code.lib.capsule_ch",
        "peekOfCode": "az = np.asarray(\n    [-1.57079633, -0.55358064, -2.12435586, -2.67794236, -2.12435586,\n     -0.55358064, -1.7595018, -1.10715248, -1.10714872, -0.55357999,\n     -1.10715248, -2.12436911, -2.48922865, -1.7595018, -2.48922865,\n     -1.10714872, 0., 0., 0., 0., 3.14159265, 3.14159265, 3.14159265,\n     3.14159265, 0., 0., 0., 0.46365119, 0., 1.01724226, 3.14159265,\n     2.58801549, 3.14159265, 2.58801549, 3.14159265, 1.01724226, 0.6523668,\n     2.03445078, 2.58801476, 2.03445078, 0.6523668, 1.38209652, 1.01722642,\n     1.57080033, 2.03444394, 2.03444394, 1.38209652, 0., 3.14159265,\n     3.14159265, 3.14159265, 0.])",
        "detail": "smplify.smplify_public.code.lib.capsule_ch",
        "documentation": {}
    },
    {
        "label": "v",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.capsule_ch",
        "description": "smplify.smplify_public.code.lib.capsule_ch",
        "peekOfCode": "v = np.vstack(\n    [np.cos(az) * np.cos(elev), np.sin(az) * np.cos(elev), np.sin(elev)]).T\nclass Capsule(object):\n    def __init__(self, t, rod, rad, length):\n        assert (hasattr(t, 'dterms'))\n        # the translation should be a chumpy object (differentiable wrt shape)\n        self.t = t  # translation of the axis\n        self.rod = rod  # rotation of the axis in Rodrigues form\n        # the radius should be a chumpy object (differentiable wrt shape)\n        assert (hasattr(rad, 'dterms'))",
        "detail": "smplify.smplify_public.code.lib.capsule_ch",
        "documentation": {}
    },
    {
        "label": "MaxMixtureComplete",
        "kind": 6,
        "importPath": "smplify.smplify_public.code.lib.max_mixture_prior",
        "description": "smplify.smplify_public.code.lib.max_mixture_prior",
        "peekOfCode": "class MaxMixtureComplete(ch.Ch):\n    \"\"\"Define the MaxMixture class.\"\"\"\n    # x is the input vector we want to evaluate the prior on;\n    # means, precs and weights are the parameters of the mixture\n    dterms = 'x'\n    terms = 'means', 'precs', 'weights'\n    def on_changed(self, which):\n        # on_changed is called before any call to r or dr_wrt,\n        # therefore it can be used also for initialization\n        # setup means, precs and loglikelihood expressions",
        "detail": "smplify.smplify_public.code.lib.max_mixture_prior",
        "documentation": {}
    },
    {
        "label": "MaxMixtureCompleteWrapper",
        "kind": 6,
        "importPath": "smplify.smplify_public.code.lib.max_mixture_prior",
        "description": "smplify.smplify_public.code.lib.max_mixture_prior",
        "peekOfCode": "class MaxMixtureCompleteWrapper(object):\n    \"\"\"Convenience wrapper to match interface spec.\"\"\"\n    def __init__(self, means, precs, weights, prefix):\n        self.means = means\n        self.precs = precs  # Already \"sqrt\"ed\n        self.weights = weights\n        self.prefix = prefix\n    def __call__(self, x):\n        # wrapping since __call__ couldn't be defined directly for a chumpy\n        # object",
        "detail": "smplify.smplify_public.code.lib.max_mixture_prior",
        "documentation": {}
    },
    {
        "label": "MaxMixtureCompletePrior",
        "kind": 6,
        "importPath": "smplify.smplify_public.code.lib.max_mixture_prior",
        "description": "smplify.smplify_public.code.lib.max_mixture_prior",
        "peekOfCode": "class MaxMixtureCompletePrior(object):\n    \"\"\"Prior density estimation.\"\"\"\n    def __init__(self, n_gaussians=8, prefix=3):\n        self.n_gaussians = n_gaussians\n        self.prefix = prefix\n        self.prior = self.create_prior_from_cmu()\n    def create_prior_from_cmu(self):\n        \"\"\"Load the gmm from the CMU motion database.\"\"\"\n        from os.path import dirname\n        import cPickle as pickle",
        "detail": "smplify.smplify_public.code.lib.max_mixture_prior",
        "documentation": {}
    },
    {
        "label": "SignedSqrt",
        "kind": 6,
        "importPath": "smplify.smplify_public.code.lib.robustifiers",
        "description": "smplify.smplify_public.code.lib.robustifiers",
        "peekOfCode": "class SignedSqrt(Ch):\n    dterms = ('x', )\n    terms = ()\n    def compute_r(self):\n        return np.sqrt(np.abs(self.x.r)) * np.sign(self.x.r)\n    def compute_dr_wrt(self, wrt):\n        if wrt is self.x:\n            result = (.5 / np.sqrt(np.abs(self.x.r)))\n            result = np.nan_to_num(result)\n            result *= (self.x.r != 0).astype(np.uint32)",
        "detail": "smplify.smplify_public.code.lib.robustifiers",
        "documentation": {}
    },
    {
        "label": "GMOfInternal",
        "kind": 6,
        "importPath": "smplify.smplify_public.code.lib.robustifiers",
        "description": "smplify.smplify_public.code.lib.robustifiers",
        "peekOfCode": "class GMOfInternal(Ch):\n    dterms = 'x', 'sigma'\n    def on_changed(self, which):\n        if 'sigma' in which:\n            assert (self.sigma.r > 0)\n        if 'x' in which:\n            self.squared_input = self.x.r**2.\n    def compute_r(self):\n        return (self.sigma.r**2 *\n                (self.squared_input /",
        "detail": "smplify.smplify_public.code.lib.robustifiers",
        "documentation": {}
    },
    {
        "label": "GMOf",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.lib.robustifiers",
        "description": "smplify.smplify_public.code.lib.robustifiers",
        "peekOfCode": "def GMOf(x, sigma):\n    \"\"\"Given x and sigma in some units (say mm),\n    returns robustified values (in same units),\n    by making use of the Geman-McClure robustifier.\"\"\"\n    result = SignedSqrt(x=GMOfInternal(x=x, sigma=sigma))\n    return result\nclass SignedSqrt(Ch):\n    dterms = ('x', )\n    terms = ()\n    def compute_r(self):",
        "detail": "smplify.smplify_public.code.lib.robustifiers",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.lib.robustifiers",
        "description": "smplify.smplify_public.code.lib.robustifiers",
        "peekOfCode": "__all__ = ['GMOf']\ndef GMOf(x, sigma):\n    \"\"\"Given x and sigma in some units (say mm),\n    returns robustified values (in same units),\n    by making use of the Geman-McClure robustifier.\"\"\"\n    result = SignedSqrt(x=GMOfInternal(x=x, sigma=sigma))\n    return result\nclass SignedSqrt(Ch):\n    dterms = ('x', )\n    terms = ()",
        "detail": "smplify.smplify_public.code.lib.robustifiers",
        "documentation": {}
    },
    {
        "label": "SphereCollisions",
        "kind": 6,
        "importPath": "smplify.smplify_public.code.lib.sphere_collisions",
        "description": "smplify.smplify_public.code.lib.sphere_collisions",
        "peekOfCode": "class SphereCollisions(ch.Ch):\n    dterms = ('pose', 'betas')\n    terms = ('regs', 'model')\n    def update_capsules_and_centers(self):\n        centers = [set_sphere_centers(capsule) for capsule in self.capsules]\n        count = 0\n        for capsule in self.capsules:\n            capsule.center_id = count\n            count += len(capsule.centers)\n        self.sph_vs = ch.vstack(centers)",
        "detail": "smplify.smplify_public.code.lib.sphere_collisions",
        "documentation": {}
    },
    {
        "label": "guess_init",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.fit_3d",
        "description": "smplify.smplify_public.code.fit_3d",
        "peekOfCode": "def guess_init(model, focal_length, j2d, init_pose):\n    \"\"\"Initialize the camera translation via triangle similarity, by using the torso joints        .\n    :param model: SMPL model\n    :param focal_length: camera focal length (kept fixed)\n    :param j2d: 14x2 array of CNN joints\n    :param init_pose: 72D vector of pose parameters used for initialization (kept fixed)\n    :returns: 3D vector corresponding to the estimated camera translation\n    \"\"\"\n    cids = np.arange(0, 12)\n    # map from LSP to SMPL joints",
        "detail": "smplify.smplify_public.code.fit_3d",
        "documentation": {}
    },
    {
        "label": "initialize_camera",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.fit_3d",
        "description": "smplify.smplify_public.code.fit_3d",
        "peekOfCode": "def initialize_camera(model,\n                      j2d,\n                      img,\n                      init_pose,\n                      flength=5000.,\n                      pix_thsh=25.,\n                      viz=False):\n    \"\"\"Initialize camera translation and body orientation\n    :param model: SMPL model\n    :param j2d: 14x2 array of CNN joints",
        "detail": "smplify.smplify_public.code.fit_3d",
        "documentation": {}
    },
    {
        "label": "optimize_on_joints",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.fit_3d",
        "description": "smplify.smplify_public.code.fit_3d",
        "peekOfCode": "def optimize_on_joints(j2d,\n                       model,\n                       cam,\n                       img,\n                       prior,\n                       try_both_orient,\n                       body_orient,\n                       n_betas=10,\n                       regs=None,\n                       conf=None,",
        "detail": "smplify.smplify_public.code.fit_3d",
        "documentation": {}
    },
    {
        "label": "run_single_fit",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.fit_3d",
        "description": "smplify.smplify_public.code.fit_3d",
        "peekOfCode": "def run_single_fit(img,\n                   j2d,\n                   conf,\n                   model,\n                   regs=None,\n                   n_betas=10,\n                   flength=5000.,\n                   pix_thsh=25.,\n                   scale_factor=1,\n                   viz=False,",
        "detail": "smplify.smplify_public.code.fit_3d",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.fit_3d",
        "description": "smplify.smplify_public.code.fit_3d",
        "peekOfCode": "def main(base_dir,\n         out_dir,\n         use_interpenetration=True,\n         n_betas=10,\n         flength=5000.,\n         pix_thsh=25.,\n         use_neutral=False,\n         viz=True):\n    \"\"\"Set up paths to image and joint data, saves results.\n    :param base_dir: folder containing LSP images and data",
        "detail": "smplify.smplify_public.code.fit_3d",
        "documentation": {}
    },
    {
        "label": "_LOGGER",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.fit_3d",
        "description": "smplify.smplify_public.code.fit_3d",
        "peekOfCode": "_LOGGER = logging.getLogger(__name__)\n# Mapping from LSP joints to SMPL joints.\n# 0 Right ankle  8\n# 1 Right knee   5\n# 2 Right hip    2\n# 3 Left hip     1\n# 4 Left knee    4\n# 5 Left ankle   7\n# 6 Right wrist  21\n# 7 Right elbow  19",
        "detail": "smplify.smplify_public.code.fit_3d",
        "documentation": {}
    },
    {
        "label": "simple_renderer",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.render_model",
        "description": "smplify.smplify_public.code.render_model",
        "peekOfCode": "def simple_renderer(rn, verts, faces, yrot=np.radians(120)):\n    # Rendered model color\n    color = colors['pink']\n    rn.set(v=verts, f=faces, vc=color, bgcolor=np.ones(3))\n    albedo = rn.vc\n    # Construct Back Light (on back right corner)\n    rn.vc = LambertianPointLight(\n        f=rn.f,\n        v=rn.v,\n        num_verts=len(rn.v),",
        "detail": "smplify.smplify_public.code.render_model",
        "documentation": {}
    },
    {
        "label": "get_alpha",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.render_model",
        "description": "smplify.smplify_public.code.render_model",
        "peekOfCode": "def get_alpha(imtmp, bgval=1.):\n    h, w = imtmp.shape[:2]\n    alpha = (~np.all(imtmp == bgval, axis=2)).astype(imtmp.dtype)\n    b_channel, g_channel, r_channel = cv2.split(imtmp)\n    im_RGBA = cv2.merge(\n        (b_channel, g_channel, r_channel, alpha.astype(imtmp.dtype)))\n    return im_RGBA\ndef render_model(verts, faces, w, h, cam, near=0.5, far=25, img=None):\n    rn = _create_renderer(\n        w=w, h=h, near=near, far=far, rt=cam.rt, t=cam.t, f=cam.f, c=cam.c)",
        "detail": "smplify.smplify_public.code.render_model",
        "documentation": {}
    },
    {
        "label": "render_model",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.render_model",
        "description": "smplify.smplify_public.code.render_model",
        "peekOfCode": "def render_model(verts, faces, w, h, cam, near=0.5, far=25, img=None):\n    rn = _create_renderer(\n        w=w, h=h, near=near, far=far, rt=cam.rt, t=cam.t, f=cam.f, c=cam.c)\n    # Uses img as background, otherwise white background.\n    if img is not None:\n        rn.background_image = img / 255. if img.max() > 1 else img\n    imtmp = simple_renderer(rn, verts, faces)\n    # If white bg, make transparent.\n    if img is None:\n        imtmp = get_alpha(imtmp)",
        "detail": "smplify.smplify_public.code.render_model",
        "documentation": {}
    },
    {
        "label": "colors",
        "kind": 5,
        "importPath": "smplify.smplify_public.code.render_model",
        "description": "smplify.smplify_public.code.render_model",
        "peekOfCode": "colors = {\n    'pink': [.7, .7, .9],\n    'neutral': [.9, .9, .8],\n    'capsule': [.7, .75, .5],\n    'yellow': [.5, .7, .75],\n}\ndef _create_renderer(w=640,\n                     h=480,\n                     rt=np.zeros(3),\n                     t=np.zeros(3),",
        "detail": "smplify.smplify_public.code.render_model",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "smplify.smplify_public.code.visualize_mesh_sequence",
        "description": "smplify.smplify_public.code.visualize_mesh_sequence",
        "peekOfCode": "def main(hdf5_path):\n    with h5py.File(hdf5_path, 'r') as f:\n        all_verts = np.array(f.get('all_verts'))\n        faces = np.array(f.get('faces'))\n    fig = mlab.figure(1, bgcolor=(1, 1, 1))\n    @mlab.animate(delay=1000, ui=True)\n    def animation():\n        for i in count():\n            frame = i % all_verts.shape[2]\n            verts = all_verts[:, :, frame].T",
        "detail": "smplify.smplify_public.code.visualize_mesh_sequence",
        "documentation": {}
    },
    {
        "label": "LPIPS",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class LPIPS(nn.Module):\n    def __init__(self, pretrained=True, net='alex', version='0.1', lpips=True, spatial=False, \n        pnet_rand=False, pnet_tune=False, use_dropout=True, model_path=None, eval_mode=True, verbose=True):\n        # lpips - [True] means with linear calibration on top of base network\n        # pretrained - [True] means load linear weights\n        super(LPIPS, self).__init__()\n        if(verbose):\n            print('Setting up [%s] perceptual loss: trunk [%s], v[%s], spatial [%s]'%\n                ('LPIPS' if lpips else 'baseline', net, version, 'on' if spatial else 'off'))\n        self.pnet_type = net",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "ScalingLayer",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class ScalingLayer(nn.Module):\n    def __init__(self):\n        super(ScalingLayer, self).__init__()\n        self.register_buffer('shift', torch.Tensor([-.030,-.088,-.188])[None,:,None,None])\n        self.register_buffer('scale', torch.Tensor([.458,.448,.450])[None,:,None,None])\n    def forward(self, inp):\n        return (inp - self.shift) / self.scale\nclass NetLinLayer(nn.Module):\n    ''' A single linear layer which does a 1x1 conv '''\n    def __init__(self, chn_in, chn_out=1, use_dropout=False):",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "NetLinLayer",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class NetLinLayer(nn.Module):\n    ''' A single linear layer which does a 1x1 conv '''\n    def __init__(self, chn_in, chn_out=1, use_dropout=False):\n        super(NetLinLayer, self).__init__()\n        layers = [nn.Dropout(),] if(use_dropout) else []\n        layers += [nn.Conv2d(chn_in, chn_out, 1, stride=1, padding=0, bias=False),]\n        self.model = nn.Sequential(*layers)\n    def forward(self, x):\n        return self.model(x)\nclass Dist2LogitLayer(nn.Module):",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "Dist2LogitLayer",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class Dist2LogitLayer(nn.Module):\n    ''' takes 2 distances, puts through fc layers, spits out value between [0,1] (if use_sigmoid is True) '''\n    def __init__(self, chn_mid=32, use_sigmoid=True):\n        super(Dist2LogitLayer, self).__init__()\n        layers = [nn.Conv2d(5, chn_mid, 1, stride=1, padding=0, bias=True),]\n        layers += [nn.LeakyReLU(0.2,True),]\n        layers += [nn.Conv2d(chn_mid, chn_mid, 1, stride=1, padding=0, bias=True),]\n        layers += [nn.LeakyReLU(0.2,True),]\n        layers += [nn.Conv2d(chn_mid, 1, 1, stride=1, padding=0, bias=True),]\n        if(use_sigmoid):",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "BCERankingLoss",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class BCERankingLoss(nn.Module):\n    def __init__(self, chn_mid=32):\n        super(BCERankingLoss, self).__init__()\n        self.net = Dist2LogitLayer(chn_mid=chn_mid)\n        # self.parameters = list(self.net.parameters())\n        self.loss = torch.nn.BCELoss()\n    def forward(self, d0, d1, judge):\n        per = (judge+1.)/2.\n        self.logit = self.net.forward(d0,d1)\n        return self.loss(self.logit, per)",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "FakeNet",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class FakeNet(nn.Module):\n    def __init__(self, use_gpu=True, colorspace='Lab'):\n        super(FakeNet, self).__init__()\n        self.use_gpu = use_gpu\n        self.colorspace = colorspace\nclass L2(FakeNet):\n    def forward(self, in0, in1, retPerLayer=None):\n        assert(in0.size()[0]==1) # currently only supports batchSize 1\n        if(self.colorspace=='RGB'):\n            (N,C,X,Y) = in0.size()",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "L2",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class L2(FakeNet):\n    def forward(self, in0, in1, retPerLayer=None):\n        assert(in0.size()[0]==1) # currently only supports batchSize 1\n        if(self.colorspace=='RGB'):\n            (N,C,X,Y) = in0.size()\n            value = torch.mean(torch.mean(torch.mean((in0-in1)**2,dim=1).view(N,1,X,Y),dim=2).view(N,1,1,Y),dim=3).view(N)\n            return value\n        elif(self.colorspace=='Lab'):\n            value = lpips.l2(lpips.tensor2np(lpips.tensor2tensorlab(in0.data,to_norm=False)), \n                lpips.tensor2np(lpips.tensor2tensorlab(in1.data,to_norm=False)), range=100.).astype('float')",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "DSSIM",
        "kind": 6,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "class DSSIM(FakeNet):\n    def forward(self, in0, in1, retPerLayer=None):\n        assert(in0.size()[0]==1) # currently only supports batchSize 1\n        if(self.colorspace=='RGB'):\n            value = lpips.dssim(1.*lpips.tensor2im(in0.data), 1.*lpips.tensor2im(in1.data), range=255.).astype('float')\n        elif(self.colorspace=='Lab'):\n            value = lpips.dssim(lpips.tensor2np(lpips.tensor2tensorlab(in0.data,to_norm=False)), \n                lpips.tensor2np(lpips.tensor2tensorlab(in1.data,to_norm=False)), range=100.).astype('float')\n        ret_var = Variable( torch.Tensor((value,) ) )\n        if(self.use_gpu):",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "spatial_average",
        "kind": 2,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "def spatial_average(in_tens, keepdim=True):\n    return in_tens.mean([2,3],keepdim=keepdim)\ndef upsample(in_tens, out_HW=(64,64)): # assumes scale factor is same for H and W\n    in_H, in_W = in_tens.shape[2], in_tens.shape[3]\n    return nn.Upsample(size=out_HW, mode='bilinear', align_corners=False)(in_tens)\n# Learned perceptual metric\nclass LPIPS(nn.Module):\n    def __init__(self, pretrained=True, net='alex', version='0.1', lpips=True, spatial=False, \n        pnet_rand=False, pnet_tune=False, use_dropout=True, model_path=None, eval_mode=True, verbose=True):\n        # lpips - [True] means with linear calibration on top of base network",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "upsample",
        "kind": 2,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "def upsample(in_tens, out_HW=(64,64)): # assumes scale factor is same for H and W\n    in_H, in_W = in_tens.shape[2], in_tens.shape[3]\n    return nn.Upsample(size=out_HW, mode='bilinear', align_corners=False)(in_tens)\n# Learned perceptual metric\nclass LPIPS(nn.Module):\n    def __init__(self, pretrained=True, net='alex', version='0.1', lpips=True, spatial=False, \n        pnet_rand=False, pnet_tune=False, use_dropout=True, model_path=None, eval_mode=True, verbose=True):\n        # lpips - [True] means with linear calibration on top of base network\n        # pretrained - [True] means load linear weights\n        super(LPIPS, self).__init__()",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "print_network",
        "kind": 2,
        "importPath": "third_parties.lpips.lpips",
        "description": "third_parties.lpips.lpips",
        "peekOfCode": "def print_network(net):\n    num_params = 0\n    for param in net.parameters():\n        num_params += param.numel()\n    print('Network',net)\n    print('Total number of parameters: %d' % num_params)",
        "detail": "third_parties.lpips.lpips",
        "documentation": {}
    },
    {
        "label": "squeezenet",
        "kind": 6,
        "importPath": "third_parties.lpips.pretrained_networks",
        "description": "third_parties.lpips.pretrained_networks",
        "peekOfCode": "class squeezenet(torch.nn.Module):\n    def __init__(self, requires_grad=False, pretrained=True):\n        super(squeezenet, self).__init__()\n        pretrained_features = tv.squeezenet1_1(pretrained=pretrained).features\n        self.slice1 = torch.nn.Sequential()\n        self.slice2 = torch.nn.Sequential()\n        self.slice3 = torch.nn.Sequential()\n        self.slice4 = torch.nn.Sequential()\n        self.slice5 = torch.nn.Sequential()\n        self.slice6 = torch.nn.Sequential()",
        "detail": "third_parties.lpips.pretrained_networks",
        "documentation": {}
    },
    {
        "label": "alexnet",
        "kind": 6,
        "importPath": "third_parties.lpips.pretrained_networks",
        "description": "third_parties.lpips.pretrained_networks",
        "peekOfCode": "class alexnet(torch.nn.Module):\n    def __init__(self, requires_grad=False, pretrained=True):\n        super(alexnet, self).__init__()\n        alexnet_pretrained_features = tv.alexnet(pretrained=pretrained).features\n        self.slice1 = torch.nn.Sequential()\n        self.slice2 = torch.nn.Sequential()\n        self.slice3 = torch.nn.Sequential()\n        self.slice4 = torch.nn.Sequential()\n        self.slice5 = torch.nn.Sequential()\n        self.N_slices = 5",
        "detail": "third_parties.lpips.pretrained_networks",
        "documentation": {}
    },
    {
        "label": "vgg16",
        "kind": 6,
        "importPath": "third_parties.lpips.pretrained_networks",
        "description": "third_parties.lpips.pretrained_networks",
        "peekOfCode": "class vgg16(torch.nn.Module):\n    def __init__(self, requires_grad=False, pretrained=True):\n        super(vgg16, self).__init__()\n        vgg_pretrained_features = tv.vgg16(pretrained=pretrained).features\n        self.slice1 = torch.nn.Sequential()\n        self.slice2 = torch.nn.Sequential()\n        self.slice3 = torch.nn.Sequential()\n        self.slice4 = torch.nn.Sequential()\n        self.slice5 = torch.nn.Sequential()\n        self.N_slices = 5",
        "detail": "third_parties.lpips.pretrained_networks",
        "documentation": {}
    },
    {
        "label": "resnet",
        "kind": 6,
        "importPath": "third_parties.lpips.pretrained_networks",
        "description": "third_parties.lpips.pretrained_networks",
        "peekOfCode": "class resnet(torch.nn.Module):\n    def __init__(self, requires_grad=False, pretrained=True, num=18):\n        super(resnet, self).__init__()\n        if(num==18):\n            self.net = tv.resnet18(pretrained=pretrained)\n        elif(num==34):\n            self.net = tv.resnet34(pretrained=pretrained)\n        elif(num==50):\n            self.net = tv.resnet50(pretrained=pretrained)\n        elif(num==101):",
        "detail": "third_parties.lpips.pretrained_networks",
        "documentation": {}
    },
    {
        "label": "clean_fn",
        "kind": 2,
        "importPath": "third_parties.smpl.models.tools.clean_ch",
        "description": "third_parties.smpl.models.tools.clean_ch",
        "peekOfCode": "def clean_fn(fn, output_folder='output'):\n    with open(fn, 'rb') as body_file:\n        # body_data = pickle.load(body_file) # 20021020: cause UnicodeDecodeError: 'ascii' codec can't decode byte 0x81 in position 1224: ordinal not in range(128)\n        body_data = pickle.load(body_file, encoding='iso-8859-1') # 20021020\n        print(body_data)\n    output_dict = {}\n    # for key, data in body_data.iteritems(): # 20021020: cause AttributeError: 'dict' object has no attribute 'iteritems'\n    for key, data in body_data.items():   # 20021020\n        if 'chumpy' in str(type(data)):\n            output_dict[key] = np.array(data)",
        "detail": "third_parties.smpl.models.tools.clean_ch",
        "documentation": {}
    },
    {
        "label": "merge_models",
        "kind": 2,
        "importPath": "third_parties.smpl.models.tools.merge_smplh_mano",
        "description": "third_parties.smpl.models.tools.merge_smplh_mano",
        "peekOfCode": "def merge_models(smplh_fn, mano_left_fn, mano_right_fn,\n                 output_folder='output'):\n    if smplh_fn.endswith('.pkl'):\n        with open(smplh_fn, 'rb') as body_file:\n            body_data = pickle.load(body_file, encoding='latin1')\n    elif smplh_fn.endswith('.npz'):\n        body_data_np = np.load(smplh_fn)\n        body_data = {}\n        for key in body_data_np:\n            body_data[key] = body_data_np[key]",
        "detail": "third_parties.smpl.models.tools.merge_smplh_mano",
        "documentation": {}
    },
    {
        "label": "SMPL",
        "kind": 6,
        "importPath": "third_parties.smpl.smpl_numpy",
        "description": "third_parties.smpl.smpl_numpy",
        "peekOfCode": "class SMPL():\n    def __init__(self, sex, model_dir):\n        super(SMPL, self).__init__()\n        model_paths = {\n            'male': os.path.join(model_dir, MALE_PATH),\n            'female': os.path.join(model_dir, FEMALE_PATH),\n            'neutral': os.path.join(model_dir, NEUTRAL_PATH)\n        }\n        with open(model_paths[sex], 'rb') as f:\n            smpl_model = pickle.load(f, encoding='latin1')",
        "detail": "third_parties.smpl.smpl_numpy",
        "documentation": {}
    },
    {
        "label": "NEUTRAL_PATH",
        "kind": 5,
        "importPath": "third_parties.smpl.smpl_numpy",
        "description": "third_parties.smpl.smpl_numpy",
        "peekOfCode": "NEUTRAL_PATH = \"basicModel_neutral_lbs_10_207_0_v1.0.0.pkl\"\nclass SMPL():\n    def __init__(self, sex, model_dir):\n        super(SMPL, self).__init__()\n        model_paths = {\n            'male': os.path.join(model_dir, MALE_PATH),\n            'female': os.path.join(model_dir, FEMALE_PATH),\n            'neutral': os.path.join(model_dir, NEUTRAL_PATH)\n        }\n        with open(model_paths[sex], 'rb') as f:",
        "detail": "third_parties.smpl.smpl_numpy",
        "documentation": {}
    },
    {
        "label": "CfgNode",
        "kind": 6,
        "importPath": "third_parties.yacs.yacs",
        "description": "third_parties.yacs.yacs",
        "peekOfCode": "class CfgNode(dict):\n    \"\"\"\n    CfgNode represents an internal node in the configuration tree. It's a simple\n    dict-like container that allows for attribute-based access to keys.\n    \"\"\"\n    IMMUTABLE = \"__immutable__\"\n    DEPRECATED_KEYS = \"__deprecated_keys__\"\n    RENAMED_KEYS = \"__renamed_keys__\"\n    def __init__(self, init_dict=None, key_list=None):\n        # Recursively convert nested dictionaries in init_dict into CfgNodes",
        "detail": "third_parties.yacs.yacs",
        "documentation": {}
    },
    {
        "label": "load_cfg",
        "kind": 2,
        "importPath": "third_parties.yacs.yacs",
        "description": "third_parties.yacs.yacs",
        "peekOfCode": "def load_cfg(cfg_file_obj_or_str):\n    \"\"\"Load a cfg. Supports loading from:\n        - A file object backed by a YAML file\n        - A file object backed by a Python source file that exports an attribute\n          \"cfg\" that is either a dict or a CfgNode\n        - A string that can be parsed as valid YAML\n    \"\"\"\n    _assert_with_logging(\n        isinstance(cfg_file_obj_or_str, _FILE_TYPES + (str,)),\n        \"Expected first argument to be of type {} or {}, but it was {}\".format(",
        "detail": "third_parties.yacs.yacs",
        "documentation": {}
    },
    {
        "label": "_PY2",
        "kind": 5,
        "importPath": "third_parties.yacs.yacs",
        "description": "third_parties.yacs.yacs",
        "peekOfCode": "_PY2 = False\n# Filename extensions for loading configs from files\n_YAML_EXTS = {\"\", \".yaml\", \".yml\"}\n_PY_EXTS = {\".py\"}\n# py2 and py3 compatibility for checking file object type\n# We simply use this to infer py2 vs py3\ntry:\n    _FILE_TYPES = (file, io.IOBase)\n    _PY2 = True\nexcept NameError:",
        "detail": "third_parties.yacs.yacs",
        "documentation": {}
    },
    {
        "label": "_YAML_EXTS",
        "kind": 5,
        "importPath": "third_parties.yacs.yacs",
        "description": "third_parties.yacs.yacs",
        "peekOfCode": "_YAML_EXTS = {\"\", \".yaml\", \".yml\"}\n_PY_EXTS = {\".py\"}\n# py2 and py3 compatibility for checking file object type\n# We simply use this to infer py2 vs py3\ntry:\n    _FILE_TYPES = (file, io.IOBase)\n    _PY2 = True\nexcept NameError:\n    _FILE_TYPES = (io.IOBase,)\n# CfgNodes can only contain a limited set of valid types",
        "detail": "third_parties.yacs.yacs",
        "documentation": {}
    },
    {
        "label": "_PY_EXTS",
        "kind": 5,
        "importPath": "third_parties.yacs.yacs",
        "description": "third_parties.yacs.yacs",
        "peekOfCode": "_PY_EXTS = {\".py\"}\n# py2 and py3 compatibility for checking file object type\n# We simply use this to infer py2 vs py3\ntry:\n    _FILE_TYPES = (file, io.IOBase)\n    _PY2 = True\nexcept NameError:\n    _FILE_TYPES = (io.IOBase,)\n# CfgNodes can only contain a limited set of valid types\n_VALID_TYPES = {tuple, list, str, int, float, bool}",
        "detail": "third_parties.yacs.yacs",
        "documentation": {}
    },
    {
        "label": "_VALID_TYPES",
        "kind": 5,
        "importPath": "third_parties.yacs.yacs",
        "description": "third_parties.yacs.yacs",
        "peekOfCode": "_VALID_TYPES = {tuple, list, str, int, float, bool}\n# py2 allow for str and unicode\nif _PY2:\n    _VALID_TYPES = _VALID_TYPES.union({unicode})  # noqa: F821\n# Utilities for importing modules from file paths\nif _PY2:\n    # imp is available in both py2 and py3 for now, but is deprecated in py3\n    import imp\nelse:\n    import importlib.util",
        "detail": "third_parties.yacs.yacs",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "third_parties.yacs.yacs",
        "description": "third_parties.yacs.yacs",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass CfgNode(dict):\n    \"\"\"\n    CfgNode represents an internal node in the configuration tree. It's a simple\n    dict-like container that allows for attribute-based access to keys.\n    \"\"\"\n    IMMUTABLE = \"__immutable__\"\n    DEPRECATED_KEYS = \"__deprecated_keys__\"\n    RENAMED_KEYS = \"__renamed_keys__\"\n    def __init__(self, init_dict=None, key_list=None):",
        "detail": "third_parties.yacs.yacs",
        "documentation": {}
    },
    {
        "label": "read_pickle",
        "kind": 2,
        "importPath": "tools.prepare_people_snapshot.prepare_dataset",
        "description": "tools.prepare_people_snapshot.prepare_dataset",
        "peekOfCode": "def read_pickle(pkl_path):\n    with open(pkl_path, 'rb') as f:\n        u = pickle._Unpickler(f)\n        u.encoding = 'latin1'\n        return u.load()\ndef parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config",
        "detail": "tools.prepare_people_snapshot.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "parse_config",
        "kind": 2,
        "importPath": "tools.prepare_people_snapshot.prepare_dataset",
        "description": "tools.prepare_people_snapshot.prepare_dataset",
        "peekOfCode": "def parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config\ndef prepare_dir(output_path, name):\n    out_dir = os.path.join(output_path, name)\n    os.makedirs(out_dir, exist_ok=True)\n    return out_dir\ndef main(argv):",
        "detail": "tools.prepare_people_snapshot.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "prepare_dir",
        "kind": 2,
        "importPath": "tools.prepare_people_snapshot.prepare_dataset",
        "description": "tools.prepare_people_snapshot.prepare_dataset",
        "peekOfCode": "def prepare_dir(output_path, name):\n    out_dir = os.path.join(output_path, name)\n    os.makedirs(out_dir, exist_ok=True)\n    return out_dir\ndef main(argv):\n    del argv  # Unused.\n    cfg = parse_config()\n    subject = cfg['dataset']['subject']\n    sex = cfg['dataset']['sex']\n    max_frames = cfg['max_frames']",
        "detail": "tools.prepare_people_snapshot.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.prepare_people_snapshot.prepare_dataset",
        "description": "tools.prepare_people_snapshot.prepare_dataset",
        "peekOfCode": "def main(argv):\n    del argv  # Unused.\n    cfg = parse_config()\n    subject = cfg['dataset']['subject']\n    sex = cfg['dataset']['sex']\n    max_frames = cfg['max_frames']\n    dataset_dir = cfg['dataset']['people_snapshot_path']\n    subject_dir = os.path.join(dataset_dir, subject)\n    output_path = os.path.join(cfg['output']['dir'], subject if 'name' not in cfg['output'].keys() else cfg['output']['name'])\n    out_img_dir = prepare_dir(output_path, 'images')",
        "detail": "tools.prepare_people_snapshot.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "FLAGS",
        "kind": 5,
        "importPath": "tools.prepare_people_snapshot.prepare_dataset",
        "description": "tools.prepare_people_snapshot.prepare_dataset",
        "peekOfCode": "FLAGS = flags.FLAGS\nflags.DEFINE_string('cfg',\n                    'male-3-casual.yaml',\n                    'the path of config file')\nMODEL_DIR = '../../third_parties/smpl/models'\ndef read_pickle(pkl_path):\n    with open(pkl_path, 'rb') as f:\n        u = pickle._Unpickler(f)\n        u.encoding = 'latin1'\n        return u.load()",
        "detail": "tools.prepare_people_snapshot.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "MODEL_DIR",
        "kind": 5,
        "importPath": "tools.prepare_people_snapshot.prepare_dataset",
        "description": "tools.prepare_people_snapshot.prepare_dataset",
        "peekOfCode": "MODEL_DIR = '../../third_parties/smpl/models'\ndef read_pickle(pkl_path):\n    with open(pkl_path, 'rb') as f:\n        u = pickle._Unpickler(f)\n        u.encoding = 'latin1'\n        return u.load()\ndef parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)",
        "detail": "tools.prepare_people_snapshot.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "parse_config",
        "kind": 2,
        "importPath": "tools.prepare_wild.prepare_dataset",
        "description": "tools.prepare_wild.prepare_dataset",
        "peekOfCode": "def parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config\ndef main(argv):\n    del argv  # Unused.\n    cfg = parse_config()\n    subject = cfg['dataset']['subject']\n    sex = cfg['dataset']['sex']",
        "detail": "tools.prepare_wild.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.prepare_wild.prepare_dataset",
        "description": "tools.prepare_wild.prepare_dataset",
        "peekOfCode": "def main(argv):\n    del argv  # Unused.\n    cfg = parse_config()\n    subject = cfg['dataset']['subject']\n    sex = cfg['dataset']['sex']\n    dataset_dir = cfg['dataset']['path']\n    subject_dir = os.path.join(dataset_dir, subject)\n    output_path = subject_dir\n    with open(os.path.join(subject_dir, 'metadata.json'), 'r') as f:\n        frame_infos = json.load(f)",
        "detail": "tools.prepare_wild.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "FLAGS",
        "kind": 5,
        "importPath": "tools.prepare_wild.prepare_dataset",
        "description": "tools.prepare_wild.prepare_dataset",
        "peekOfCode": "FLAGS = flags.FLAGS\nflags.DEFINE_string('cfg',\n                    'wild.yaml',\n                    'the path of config file')\nMODEL_DIR = '../../third_parties/smpl/models'\ndef parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config",
        "detail": "tools.prepare_wild.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "MODEL_DIR",
        "kind": 5,
        "importPath": "tools.prepare_wild.prepare_dataset",
        "description": "tools.prepare_wild.prepare_dataset",
        "peekOfCode": "MODEL_DIR = '../../third_parties/smpl/models'\ndef parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config\ndef main(argv):\n    del argv  # Unused.\n    cfg = parse_config()\n    subject = cfg['dataset']['subject']",
        "detail": "tools.prepare_wild.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "parse_config",
        "kind": 2,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "def parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config\ndef prepare_dir(output_path, name):\n    out_dir = os.path.join(output_path, name)\n    os.makedirs(out_dir, exist_ok=True)\n    return out_dir\ndef get_mask(subject_dir, img_name):",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "prepare_dir",
        "kind": 2,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "def prepare_dir(output_path, name):\n    out_dir = os.path.join(output_path, name)\n    os.makedirs(out_dir, exist_ok=True)\n    return out_dir\ndef get_mask(subject_dir, img_name):\n    msk_path = os.path.join(subject_dir, 'mask',\n                            img_name)[:-4] + '.png'\n    msk = np.array(load_image(msk_path))[:, :, 0]\n    msk = (msk != 0).astype(np.uint8)\n    msk_path = os.path.join(subject_dir, 'mask_cihp',",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "get_mask",
        "kind": 2,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "def get_mask(subject_dir, img_name):\n    msk_path = os.path.join(subject_dir, 'mask',\n                            img_name)[:-4] + '.png'\n    msk = np.array(load_image(msk_path))[:, :, 0]\n    msk = (msk != 0).astype(np.uint8)\n    msk_path = os.path.join(subject_dir, 'mask_cihp',\n                            img_name)[:-4] + '.png'\n    msk_cihp = np.array(load_image(msk_path))[:, :, 0]\n    msk_cihp = (msk_cihp != 0).astype(np.uint8)\n    msk = (msk | msk_cihp).astype(np.uint8)",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "encode_motions",
        "kind": 2,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "def encode_motions(model, motions, device):\n    # z = model.encoder({'x': motions,'y': torch.zeros(motions.shape[0], dtype=int, device=device),'mask': model.lengths_to_mask(torch.ones(motions.shape[0], dtype=int, device=device) * 60)})[\"mu\"]\n    # all_tokens = model.encoder({'x': motions,'y': torch.zeros(motions.shape[0], dtype=int, device=device),'mask': model.lengths_to_mask(torch.ones(motions.shape[0], dtype=int, device=device) * 60)})[\"all\"]\n    output = model.encoder({'x': motions,'y': torch.zeros(motions.shape[0], dtype=int, device=device),'mask': model.lengths_to_mask(torch.ones(motions.shape[0], dtype=int, device=device) * 60)})\n    # breakpoint()\n    return output\ndef get_encode_motions(poses_axis_angle, neighborhood, ZorSelf):\n    # neighborhood 1: each frame encodes its clip feature independently\n    # neighborhood odds within [1,59]\n    # ZorSelf: True for z token; False for token of each frame",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "get_encode_motions",
        "kind": 2,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "def get_encode_motions(poses_axis_angle, neighborhood, ZorSelf):\n    # neighborhood 1: each frame encodes its clip feature independently\n    # neighborhood odds within [1,59]\n    # ZorSelf: True for z token; False for token of each frame\n    assert neighborhood % 2 != 0 and 1 <= neighborhood <= 59, 'unreasonable neighborhood!!! should be odds within [1,59]'\n    numPoses = len(poses_axis_angle)\n    input_features = torch.zeros(numPoses, 25, 6).float().cuda()\n    print('transform each pose from axis_angle to 6d...')  \n    dummy_translation = torch.zeros(1, 6).float().cuda()\n    for idx, ipose in enumerate(tqdm(poses_axis_angle)):",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "def main(argv):\n    del argv  # Unused.\n    cfg = parse_config()\n    subject = cfg['dataset']['subject']\n    sex = cfg['dataset']['sex']\n    max_frames = cfg['max_frames']\n    dataset_dir = cfg['dataset']['zju_mocap_path']\n    subject_dir = os.path.join(dataset_dir, f\"CoreView_{subject}\")\n    smpl_params_dir = os.path.join(subject_dir, \"new_params\")            # smpl parameters\n    anno_path = os.path.join(subject_dir, 'annots.npy')",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "FLAGS",
        "kind": 5,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "FLAGS = flags.FLAGS\nimport torch.nn as nn\nflags.DEFINE_string('cfg', '387.yaml', 'the path of config file')\nMODEL_DIR = '../../third_parties/smpl/models'\ndef parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config\ndef prepare_dir(output_path, name):",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "MODEL_DIR",
        "kind": 5,
        "importPath": "tools.prepare_zju_mocap.prepare_dataset",
        "description": "tools.prepare_zju_mocap.prepare_dataset",
        "peekOfCode": "MODEL_DIR = '../../third_parties/smpl/models'\ndef parse_config():\n    config = None\n    with open(FLAGS.cfg, 'r') as file:\n        config = yaml.full_load(file)\n    return config\ndef prepare_dir(output_path, name):\n    out_dir = os.path.join(output_path, name)\n    os.makedirs(out_dir, exist_ok=True)\n    return out_dir",
        "detail": "tools.prepare_zju_mocap.prepare_dataset",
        "documentation": {}
    },
    {
        "label": "global_rigid_transformation",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.lbs",
        "description": "tools.snapshot_smpl.vendor.smpl.lbs",
        "peekOfCode": "def global_rigid_transformation(pose, J, kintree_table, xp):\n    results = {}\n    pose = pose.reshape((-1,3))\n    id_to_col = {kintree_table[1,i] : i for i in range(kintree_table.shape[1])}\n    parent = {i : id_to_col[kintree_table[0,i]] for i in range(1, kintree_table.shape[1])}\n    if xp == chumpy:\n        from posemapper import Rodrigues\n        rodrigues = lambda x : Rodrigues(x)\n    else:\n        import cv2",
        "detail": "tools.snapshot_smpl.vendor.smpl.lbs",
        "documentation": {}
    },
    {
        "label": "verts_core",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.lbs",
        "description": "tools.snapshot_smpl.vendor.smpl.lbs",
        "peekOfCode": "def verts_core(pose, v, J, weights, kintree_table, want_Jtr=False, xp=chumpy):\n    A, A_global = global_rigid_transformation(pose, J, kintree_table, xp)\n    T = A.dot(weights.T)\n    rest_shape_h = xp.vstack((v.T, np.ones((1, v.shape[0]))))\n    v =(T[:,0,:] * rest_shape_h[0, :].reshape((1, -1)) +\n        T[:,1,:] * rest_shape_h[1, :].reshape((1, -1)) +\n        T[:,2,:] * rest_shape_h[2, :].reshape((1, -1)) +\n        T[:,3,:] * rest_shape_h[3, :].reshape((1, -1))).T\n    v = v[:,:3]\n    if not want_Jtr:",
        "detail": "tools.snapshot_smpl.vendor.smpl.lbs",
        "documentation": {}
    },
    {
        "label": "Rodrigues",
        "kind": 6,
        "importPath": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "description": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "peekOfCode": "class Rodrigues(ch.Ch):\n    dterms = 'rt'\n    def compute_r(self):\n        return cv2.Rodrigues(self.rt.r)[0]\n    def compute_dr_wrt(self, wrt):\n        if wrt is self.rt:\n            return cv2.Rodrigues(self.rt.r)[1].T\ndef lrotmin(p): \n    if isinstance(p, np.ndarray):\n        p = p.ravel()[3:]",
        "detail": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "documentation": {}
    },
    {
        "label": "lrotmin",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "description": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "peekOfCode": "def lrotmin(p): \n    if isinstance(p, np.ndarray):\n        p = p.ravel()[3:]\n        return np.concatenate([(cv2.Rodrigues(np.array(pp))[0]-np.eye(3)).ravel() for pp in p.reshape((-1,3))]).ravel()        \n    if p.ndim != 2 or p.shape[1] != 3:\n        p = p.reshape((-1,3))\n    p = p[1:]\n    return ch.concatenate([(Rodrigues(pp)-ch.eye(3)).ravel() for pp in p]).ravel()\ndef posemap(s):\n    if s == 'lrotmin':",
        "detail": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "documentation": {}
    },
    {
        "label": "posemap",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "description": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "peekOfCode": "def posemap(s):\n    if s == 'lrotmin':\n        return lrotmin\n    else:\n        raise Exception('Unknown posemapping: %s' % (str(s),))",
        "detail": "tools.snapshot_smpl.vendor.smpl.posemapper",
        "documentation": {}
    },
    {
        "label": "save_model",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.serialization",
        "description": "tools.snapshot_smpl.vendor.smpl.serialization",
        "peekOfCode": "def save_model(model, fname):\n    m0 = model\n    trainer_dict = {'v_template': np.asarray(m0.v_template),'J': np.asarray(m0.J),'weights': np.asarray(m0.weights),'kintree_table': m0.kintree_table,'f': m0.f, 'bs_type': m0.bs_type, 'posedirs': np.asarray(m0.posedirs)}\n    if hasattr(model, 'J_regressor'):\n        trainer_dict['J_regressor'] = m0.J_regressor\n    if hasattr(model, 'J_regressor_prior'):\n        trainer_dict['J_regressor_prior'] = m0.J_regressor_prior\n    if hasattr(model, 'weights_prior'):\n        trainer_dict['weights_prior'] = m0.weights_prior\n    if hasattr(model, 'shapedirs'):",
        "detail": "tools.snapshot_smpl.vendor.smpl.serialization",
        "documentation": {}
    },
    {
        "label": "backwards_compatibility_replacements",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.serialization",
        "description": "tools.snapshot_smpl.vendor.smpl.serialization",
        "peekOfCode": "def backwards_compatibility_replacements(dd):\n    # replacements\n    if 'default_v' in dd:\n        dd['v_template'] = dd['default_v']\n        del dd['default_v']\n    if 'template_v' in dd:\n        dd['v_template'] = dd['template_v']\n        del dd['template_v']\n    if 'joint_regressor' in dd:\n        dd['J_regressor'] = dd['joint_regressor']",
        "detail": "tools.snapshot_smpl.vendor.smpl.serialization",
        "documentation": {}
    },
    {
        "label": "ready_arguments",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.serialization",
        "description": "tools.snapshot_smpl.vendor.smpl.serialization",
        "peekOfCode": "def ready_arguments(fname_or_dict):\n    if not isinstance(fname_or_dict, dict):\n        dd = pickle.load(open(fname_or_dict))\n    else:\n        dd = fname_or_dict\n    backwards_compatibility_replacements(dd)\n    want_shapemodel = 'shapedirs' in dd\n    nposeparms = dd['kintree_table'].shape[1]*3\n    if 'trans' not in dd:\n        dd['trans'] = np.zeros(3)",
        "detail": "tools.snapshot_smpl.vendor.smpl.serialization",
        "documentation": {}
    },
    {
        "label": "load_model",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.serialization",
        "description": "tools.snapshot_smpl.vendor.smpl.serialization",
        "peekOfCode": "def load_model(fname_or_dict):\n    dd = ready_arguments(fname_or_dict)\n    args = {\n        'pose': dd['pose'],\n        'v': dd['v_posed'],\n        'J': dd['J'],\n        'weights': dd['weights'],\n        'kintree_table': dd['kintree_table'],\n        'xp': ch,\n        'want_Jtr': True,",
        "detail": "tools.snapshot_smpl.vendor.smpl.serialization",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "tools.snapshot_smpl.vendor.smpl.serialization",
        "description": "tools.snapshot_smpl.vendor.smpl.serialization",
        "peekOfCode": "__all__ = ['load_model', 'save_model']\nimport numpy as np\nimport pickle\nimport chumpy as ch\nfrom chumpy.ch import MatVecMult\nfrom .posemapper import posemap\nfrom .verts import verts_core\ndef save_model(model, fname):\n    m0 = model\n    trainer_dict = {'v_template': np.asarray(m0.v_template),'J': np.asarray(m0.J),'weights': np.asarray(m0.weights),'kintree_table': m0.kintree_table,'f': m0.f, 'bs_type': m0.bs_type, 'posedirs': np.asarray(m0.posedirs)}",
        "detail": "tools.snapshot_smpl.vendor.smpl.serialization",
        "documentation": {}
    },
    {
        "label": "ischumpy",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.verts",
        "description": "tools.snapshot_smpl.vendor.smpl.verts",
        "peekOfCode": "def ischumpy(x): return hasattr(x, 'dterms')\ndef verts_decorated(trans, pose,\n    v_template, J, weights, kintree_table, bs_style, f,\n    bs_type=None, posedirs=None, betas=None, shapedirs=None, want_Jtr=False):\n    for which in [trans, pose, v_template, weights, posedirs, betas, shapedirs]:\n        if which is not None:\n            assert ischumpy(which)\n    v = v_template\n    if shapedirs is not None:\n        if betas is None:",
        "detail": "tools.snapshot_smpl.vendor.smpl.verts",
        "documentation": {}
    },
    {
        "label": "verts_decorated",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.verts",
        "description": "tools.snapshot_smpl.vendor.smpl.verts",
        "peekOfCode": "def verts_decorated(trans, pose,\n    v_template, J, weights, kintree_table, bs_style, f,\n    bs_type=None, posedirs=None, betas=None, shapedirs=None, want_Jtr=False):\n    for which in [trans, pose, v_template, weights, posedirs, betas, shapedirs]:\n        if which is not None:\n            assert ischumpy(which)\n    v = v_template\n    if shapedirs is not None:\n        if betas is None:\n            betas = chumpy.zeros(shapedirs.shape[-1])",
        "detail": "tools.snapshot_smpl.vendor.smpl.verts",
        "documentation": {}
    },
    {
        "label": "verts_core",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.vendor.smpl.verts",
        "description": "tools.snapshot_smpl.vendor.smpl.verts",
        "peekOfCode": "def verts_core(pose, v, J, weights, kintree_table, bs_style, want_Jtr=False, xp=chumpy):\n    if xp == chumpy:\n        assert(hasattr(pose, 'dterms'))\n        assert(hasattr(v, 'dterms'))\n        assert(hasattr(J, 'dterms'))\n        assert(hasattr(weights, 'dterms'))\n    assert(bs_style=='lbs')\n    result = lbs.verts_core(pose, v, J, weights, kintree_table, want_Jtr, xp)\n    return result",
        "detail": "tools.snapshot_smpl.vendor.smpl.verts",
        "documentation": {}
    },
    {
        "label": "Renderer",
        "kind": 6,
        "importPath": "tools.snapshot_smpl.renderer",
        "description": "tools.snapshot_smpl.renderer",
        "peekOfCode": "class Renderer(object):\n    def __init__(self, focal_length=1000, height=512, width=512, faces=None):\n        self.renderer = pyrender.OffscreenRenderer(height, width)\n        self.faces = faces\n        self.focal_length = focal_length\n    def render_multiview(self, vertices, K, R, T, imglist, return_depth=False):\n        # List to store rendered scenes\n        output_images, output_depths = [], []\n        # Need to flip x-axis\n        rot = trimesh.transformations.rotation_matrix(",
        "detail": "tools.snapshot_smpl.renderer",
        "documentation": {}
    },
    {
        "label": "colors",
        "kind": 5,
        "importPath": "tools.snapshot_smpl.renderer",
        "description": "tools.snapshot_smpl.renderer",
        "peekOfCode": "colors = [\n    (0.5, 0.2, 0.2, 1.0),  # Defalut\n    (.7, .5, .5, 1.),  # Pink\n    (.7, .7, .6, 1.),  # Neutral\n    (.5, .5, .7, 1.),  # Blue\n    (.5, .55, .3, 1.),  # capsule\n    (.3, .5, .55, 1.),  # Yellow\n]\nclass Renderer(object):\n    def __init__(self, focal_length=1000, height=512, width=512, faces=None):",
        "detail": "tools.snapshot_smpl.renderer",
        "documentation": {}
    },
    {
        "label": "Smpl",
        "kind": 6,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "class Smpl(Ch):\n    \"\"\"\n    Class to store SMPL object with slightly improved code and access to more matrices\n    \"\"\"\n    terms = 'model',\n    dterms = 'trans', 'betas', 'pose', 'v_personal'\n    def __init__(self, *args, **kwargs):\n        self.on_changed(self._dirty_vars)\n    def on_changed(self, which):\n        if not hasattr(self, 'trans'):",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "copy_smpl",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "def copy_smpl(smpl, model):\n    new = Smpl(model, betas=smpl.betas)\n    new.pose[:] = smpl.pose.r\n    new.trans[:] = smpl.trans.r\n    return new\ndef joints_coco(smpl):\n    J = smpl.J_transformed\n    nose = smpl[VERT_NOSE]\n    ear_l = smpl[VERT_EAR_L]\n    ear_r = smpl[VERT_EAR_R]",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "joints_coco",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "def joints_coco(smpl):\n    J = smpl.J_transformed\n    nose = smpl[VERT_NOSE]\n    ear_l = smpl[VERT_EAR_L]\n    ear_r = smpl[VERT_EAR_R]\n    eye_l = smpl[VERT_EYE_L]\n    eye_r = smpl[VERT_EYE_R]\n    shoulders_m = ch.sum(J[[14, 13]], axis=0) / 2.\n    neck = J[12] - 0.55 * (J[12] - shoulders_m)\n    return ch.vstack((",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "model_params_in_camera_coords",
        "kind": 2,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "def model_params_in_camera_coords(trans, pose, J0, camera_t, camera_rt):\n    root = Rodrigues(np.matmul(Rodrigues(camera_rt).r, Rodrigues(pose[:3]).r)).r.reshape(-1)\n    pose[:3] = root\n    trans = (Rodrigues(camera_rt).dot(J0 + trans) - J0 + camera_t).r\n    return trans, pose\nif __name__ == '__main__':\n    smpl = Smpl(model='../vendor/smpl/models/basicModel_f_lbs_10_207_0_v1.0.0.pkl')\n    smpl.pose[:] = np.random.randn(72) * .2\n    smpl.pose[0] = np.pi\n    # smpl.v_personal[:] = np.random.randn(*smpl.shape) / 500.",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "VERT_NOSE",
        "kind": 5,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "VERT_NOSE = 331\nVERT_EAR_L = 3485\nVERT_EAR_R = 6880\nVERT_EYE_L = 2802\nVERT_EYE_R = 6262\nclass Smpl(Ch):\n    \"\"\"\n    Class to store SMPL object with slightly improved code and access to more matrices\n    \"\"\"\n    terms = 'model',",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "VERT_EAR_L",
        "kind": 5,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "VERT_EAR_L = 3485\nVERT_EAR_R = 6880\nVERT_EYE_L = 2802\nVERT_EYE_R = 6262\nclass Smpl(Ch):\n    \"\"\"\n    Class to store SMPL object with slightly improved code and access to more matrices\n    \"\"\"\n    terms = 'model',\n    dterms = 'trans', 'betas', 'pose', 'v_personal'",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "VERT_EAR_R",
        "kind": 5,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "VERT_EAR_R = 6880\nVERT_EYE_L = 2802\nVERT_EYE_R = 6262\nclass Smpl(Ch):\n    \"\"\"\n    Class to store SMPL object with slightly improved code and access to more matrices\n    \"\"\"\n    terms = 'model',\n    dterms = 'trans', 'betas', 'pose', 'v_personal'\n    def __init__(self, *args, **kwargs):",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "VERT_EYE_L",
        "kind": 5,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "VERT_EYE_L = 2802\nVERT_EYE_R = 6262\nclass Smpl(Ch):\n    \"\"\"\n    Class to store SMPL object with slightly improved code and access to more matrices\n    \"\"\"\n    terms = 'model',\n    dterms = 'trans', 'betas', 'pose', 'v_personal'\n    def __init__(self, *args, **kwargs):\n        self.on_changed(self._dirty_vars)",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "VERT_EYE_R",
        "kind": 5,
        "importPath": "tools.snapshot_smpl.smpl",
        "description": "tools.snapshot_smpl.smpl",
        "peekOfCode": "VERT_EYE_R = 6262\nclass Smpl(Ch):\n    \"\"\"\n    Class to store SMPL object with slightly improved code and access to more matrices\n    \"\"\"\n    terms = 'model',\n    dterms = 'trans', 'betas', 'pose', 'v_personal'\n    def __init__(self, *args, **kwargs):\n        self.on_changed(self._dirty_vars)\n    def on_changed(self, which):",
        "detail": "tools.snapshot_smpl.smpl",
        "documentation": {}
    },
    {
        "label": "set_requires_grad",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def set_requires_grad(nets, requires_grad=False):\n    if not isinstance(nets, list):\n        nets = [nets]\n    for net in nets:\n        if net is not None:\n            for param in net.parameters():\n                param.requires_grad = requires_grad\ndef load_network(checkpoint):\n    model = create_network()\n    ckpt_path = os.path.join(cfg.logdir, f'{checkpoint}.tar')",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "load_network",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def load_network(checkpoint):\n    model = create_network()\n    ckpt_path = os.path.join(cfg.logdir, f'{checkpoint}.tar')\n    ckpt = torch.load(ckpt_path, map_location='cuda:0')\n    model.load_state_dict(ckpt['network'], strict=False)\n    print('load network from ', ckpt_path)\n    return model.cuda().deploy_mlps_to_secondary_gpus()\ndef unpack_alpha_map(alpha_vals, ray_mask, width, height):\n    alpha_map = np.zeros((height * width), dtype='float32')\n    alpha_map[ray_mask] = alpha_vals",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "unpack_alpha_map",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def unpack_alpha_map(alpha_vals, ray_mask, width, height):\n    alpha_map = np.zeros((height * width), dtype='float32')\n    alpha_map[ray_mask] = alpha_vals\n    return alpha_map.reshape((height, width))\ndef unpack_to_image(width, height, ray_mask, bgcolor, rgb, alpha, truth=None):\n    rgb_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    truth_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    rgb_image[ray_mask] = rgb\n    rgb_image = to_8b_image(rgb_image.reshape((height, width, 3)))\n    if truth is not None:",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "unpack_to_image",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def unpack_to_image(width, height, ray_mask, bgcolor, rgb, alpha, truth=None):\n    rgb_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    truth_image = np.full((height * width, 3), bgcolor, dtype='float32')\n    rgb_image[ray_mask] = rgb\n    rgb_image = to_8b_image(rgb_image.reshape((height, width, 3)))\n    if truth is not None:\n        truth_image[ray_mask] = truth\n        truth_image = to_8b_image(truth_image.reshape((height, width, 3)))\n    alpha_map = unpack_alpha_map(alpha, ray_mask, width, height)\n    alpha_image = to_8b3ch_image(alpha_map)",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "psnr_metric",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def psnr_metric(img_pred, img_gt):\n    ''' Calculate psnr metric\n        Args:\n            img_pred: ndarray, W*H*3, range 0-1\n            img_gt: ndarray, W*H*3, range 0-1\n        Returns:\n            psnr metric: scalar\n    '''\n    mse = np.mean((img_pred - img_gt) ** 2)\n    psnr = -10 * np.log(mse) / np.log(10)",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "lpips_metric",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def lpips_metric(model, pred, target):\n    # convert range from 0-1 to -1-1\n    processed_pred = torch.from_numpy(pred).float().unsqueeze(0).to(cfg.primary_gpus[0]) * 2. - 1.\n    processed_target=torch.from_numpy(target).float().unsqueeze(0).to(cfg.primary_gpus[0]) * 2. - 1.\n    lpips_loss = model(processed_pred.permute(0, 3, 1, 2), processed_target.permute(0, 3, 1, 2))\n    return torch.mean(lpips_loss).cpu().detach().item()\ndef save_result_yaml(file_name, result):\n    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n    with open(file_name, \"w\") as f:\n        yaml.dump(result, f) ",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "save_result_yaml",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def save_result_yaml(file_name, result):\n    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n    with open(file_name, \"w\") as f:\n        yaml.dump(result, f) \ndef eval_model(render_folder_name='eval'):\n    cfg.perturb = 0.\n    only_latest = False\n    checkpoint_paths = sorted(glob.glob(os.path.join(cfg.logdir, '*.tar')), key=os.path.getmtime)\n    print(checkpoint_paths)\n    checkpoint_num = len(checkpoint_paths)",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "eval_model",
        "kind": 2,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "def eval_model(render_folder_name='eval'):\n    cfg.perturb = 0.\n    only_latest = False\n    checkpoint_paths = sorted(glob.glob(os.path.join(cfg.logdir, '*.tar')), key=os.path.getmtime)\n    print(checkpoint_paths)\n    checkpoint_num = len(checkpoint_paths)\n    test_loader = create_dataloader('movement')\n    log_dir = os.path.join(cfg.logdir, 'logs')\n    swriter = SummaryWriter(log_dir)\n    lpips_model = LPIPS(net='vgg')",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "EXCLUDE_KEYS_TO_GPU",
        "kind": 5,
        "importPath": "eval",
        "description": "eval",
        "peekOfCode": "EXCLUDE_KEYS_TO_GPU = ['frame_name', 'img_width', 'img_height', 'ray_mask']\ndef set_requires_grad(nets, requires_grad=False):\n    if not isinstance(nets, list):\n        nets = [nets]\n    for net in nets:\n        if net is not None:\n            for param in net.parameters():\n                param.requires_grad = requires_grad\ndef load_network(checkpoint):\n    model = create_network()",
        "detail": "eval",
        "documentation": {}
    },
    {
        "label": "make_deterministic",
        "kind": 2,
        "importPath": "train",
        "description": "train",
        "peekOfCode": "def make_deterministic(seed):\n    '''Seed everything for better reproducibility.\n    (some pytorch operation is non-deterministic like the backprop of grid_samples)\n    '''\n    seed=int(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed) # sets the seed for generating random numbers.\n    torch.cuda.manual_seed(seed) # Sets the seed for generating random numbers for the current GPU. It’s safe to call this function if CUDA is not available; in that case, it is silently ignored.\n    torch.cuda.manual_seed_all(seed) # Sets the seed for generating random numbers on all GPUs. It’s safe to call this function if CUDA is not available; in that case, it is silently ignored.",
        "detail": "train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "train",
        "description": "train",
        "peekOfCode": "def main():\n    log = Logger()\n    log.print_config()\n    print('fixed random seed: %d' % cfg.train.seed)\n    make_deterministic(cfg.train.seed)\n    model = create_network()\n    optimizer = create_optimizer(model)\n    trainer = create_trainer(model, optimizer)\n    train_loader = create_dataloader('train')\n    # estimate start epoch",
        "detail": "train",
        "documentation": {}
    },
    {
        "label": "set_random_seed",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def set_random_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\ndef render_image_with_occgrid(\n    # scene\n    radiance_field: torch.nn.Module,\n    estimator: OccGridEstimator,\n    rays_o: Rays,\n    rays_d: Rays,",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "render_image_with_occgrid",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def render_image_with_occgrid(\n    # scene\n    radiance_field: torch.nn.Module,\n    estimator: OccGridEstimator,\n    rays_o: Rays,\n    rays_d: Rays,\n    # rendering options\n    near_plane: float = 0.0,\n    far_plane: float = 1e10,\n    render_step_size: float = 1e-3,",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "render_image_with_propnet",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def render_image_with_propnet(\n    # scene\n    radiance_field: torch.nn.Module,\n    proposal_networks: Sequence[torch.nn.Module],\n    estimator: PropNetEstimator,\n    rays: Rays,\n    # rendering options\n    num_samples: int,\n    num_samples_per_prop: Sequence[int],\n    near_plane: Optional[float] = None,",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "render_image_with_occgrid_test",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def render_image_with_occgrid_test(\n    max_samples: int,\n    # scene\n    radiance_field: torch.nn.Module,\n    estimator: OccGridEstimator,\n    rays: Rays,\n    # rendering options\n    near_plane: float = 0.0,\n    far_plane: float = 1e10,\n    render_step_size: float = 1e-3,",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "NERF_SYNTHETIC_SCENES",
        "kind": 5,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "NERF_SYNTHETIC_SCENES = [\n    \"chair\",\n    \"drums\",\n    \"ficus\",\n    \"hotdog\",\n    \"lego\",\n    \"materials\",\n    \"mic\",\n    \"ship\",\n]",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "MIPNERF360_UNBOUNDED_SCENES",
        "kind": 5,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "MIPNERF360_UNBOUNDED_SCENES = [\n    \"garden\",\n    \"bicycle\",\n    \"bonsai\",\n    \"counter\",\n    \"kitchen\",\n    \"room\",\n    \"stump\",\n]\ndef set_random_seed(seed):",
        "detail": "utils",
        "documentation": {}
    }
]